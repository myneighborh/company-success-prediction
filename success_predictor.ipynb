{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID ì»¬ëŸ¼ ë¶„ë¦¬\n",
    "train = train.drop(columns=['ID'], axis = 1)\n",
    "test = test.drop(columns=['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_valuation(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    if 'ì´ìƒ' in val:\n",
    "        # '6000ì´ìƒ' â†’ 6000\n",
    "        return int(re.sub('[^0-9]', '', val))\n",
    "    elif '-' in val:\n",
    "        # '2500-3500' â†’ í‰ê· ê°’ ê³„ì‚°\n",
    "        low, high = map(int, val.split('-'))\n",
    "        return (low + high) / 2\n",
    "    else:\n",
    "        # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ê²½ìš°\n",
    "        try:\n",
    "            return float(val)\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ë¦½ì—°ë„ -> ì—°ì°¨ë¡œ ë³€ê²½\n",
    "current_year = 2025\n",
    "\n",
    "train['ì—°ì°¨'] = current_year - train['ì„¤ë¦½ì—°ë„']\n",
    "test['ì—°ì°¨'] = current_year - test['ì„¤ë¦½ì—°ë„']\n",
    "\n",
    "# ì„¤ë¦½ì—°ë„ ì œê±°\n",
    "train.drop(columns = ['ì„¤ë¦½ì—°ë„'], inplace = True)\n",
    "test.drop(columns = ['ì„¤ë¦½ì—°ë„'], inplace = True)\n",
    "\n",
    "category_features = ['êµ­ê°€','ë¶„ì•¼']\n",
    "numeric_features = ['ì—°ì°¨', 'íˆ¬ìë‹¨ê³„', 'ì§ì› ìˆ˜','ê³ ê°ìˆ˜(ë°±ë§Œëª…)','ì´ íˆ¬ìê¸ˆ(ì–µì›)','ì—°ë§¤ì¶œ(ì–µì›)','SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "bool_features = ['ì¸ìˆ˜ì—¬ë¶€','ìƒì¥ì—¬ë¶€']\n",
    "\n",
    "# íˆ¬ìë‹¨ê³„ ìˆœì„œë¥¼ ìˆ«ìë¡œ ë§¤í•‘\n",
    "investment_stage_map = {\n",
    "    'Seed': 0,\n",
    "    'Series A': 1,\n",
    "    'Series B': 2,\n",
    "    'Series C': 3,\n",
    "    'IPO': 4,\n",
    "    'Missing': -1\n",
    "}\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ë¨¼ì € ì²˜ë¦¬ í›„ ë§¤í•‘\n",
    "train['íˆ¬ìë‹¨ê³„'] = train['íˆ¬ìë‹¨ê³„'].fillna('Missing').map(investment_stage_map)\n",
    "test['íˆ¬ìë‹¨ê³„'] = test['íˆ¬ìë‹¨ê³„'].fillna('Missing').map(investment_stage_map)\n",
    "\n",
    "# ê¸°ì—…ê°€ì¹˜ ë³€í™˜\n",
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(clean_valuation)\n",
    "test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(clean_valuation)\n",
    "\n",
    "# LabelEncoder ê°ì²´ë¥¼ ê° ë²”ì£¼í˜• featureë³„ë¡œ ë”°ë¡œ ì €ì¥í•˜ì—¬ ì‚¬ìš©\n",
    "encoders = {}\n",
    "\n",
    "# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ encoding\n",
    "for feature in category_features:\n",
    "    encoders[feature] = LabelEncoder()\n",
    "    train[feature] = train[feature].fillna('Missing')\n",
    "    test[feature] = test[feature].fillna('Missing')\n",
    "    train[feature] = encoders[feature].fit_transform(train[feature])\n",
    "    test[feature] = encoders[feature].transform(test[feature])\n",
    "\n",
    "# ë¶ˆë¦¬ì–¸ ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ ('Yes' â†’ 1, 'No' â†’ 0 ìœ¼ë¡œ ë³€í™˜)\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "\n",
    "for feature in bool_features:\n",
    "    train[feature] = train[feature].map(bool_map)\n",
    "    test[feature] = test[feature].map(bool_map)\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ë¥¼ ì¤‘ê°„ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "for feature in numeric_features:\n",
    "    median_value = train[feature].median()\n",
    "    train[feature] = train[feature].fillna(median_value)\n",
    "    test[feature] = test[feature].fillna(median_value)\n",
    "\n",
    "# TabNetìš© ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ë±ìŠ¤(cat_idxs) ë° ì°¨ì›(cat_dims) ì„¤ì •\n",
    "features = [col for col in train.columns if col != 'ì„±ê³µí™•ë¥ ']\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [train[col].max() + 1 for col in category_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ë¦½ì—°ë„ -> ì—°ì°¨ë¡œ ë³€ê²½\n",
    "current_year = 2025\n",
    "\n",
    "train['ì—°ì°¨'] = current_year - train['ì„¤ë¦½ì—°ë„']\n",
    "test['ì—°ì°¨'] = current_year - test['ì„¤ë¦½ì—°ë„']\n",
    "\n",
    "# ì„¤ë¦½ì—°ë„ ì œê±°\n",
    "train.drop(columns = ['ì„¤ë¦½ì—°ë„'], inplace = True)\n",
    "test.drop(columns = ['ì„¤ë¦½ì—°ë„'], inplace = True)\n",
    "\n",
    "category_features = ['êµ­ê°€','ë¶„ì•¼']\n",
    "numeric_features = ['ì—°ì°¨', 'íˆ¬ìë‹¨ê³„', 'ì§ì› ìˆ˜','ê³ ê°ìˆ˜(ë°±ë§Œëª…)','ì´ íˆ¬ìê¸ˆ(ì–µì›)','ì—°ë§¤ì¶œ(ì–µì›)','SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "bool_features = ['ì¸ìˆ˜ì—¬ë¶€','ìƒì¥ì—¬ë¶€']\n",
    "\n",
    "# íˆ¬ìë‹¨ê³„ ìˆœì„œë¥¼ ìˆ«ìë¡œ ë§¤í•‘\n",
    "investment_stage_map = {\n",
    "    'Seed': 0,\n",
    "    'Series A': 1,\n",
    "    'Series B': 2,\n",
    "    'Series C': 3,\n",
    "    'IPO': 4,\n",
    "    'Missing': -1\n",
    "}\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ë¨¼ì € ì²˜ë¦¬ í›„ ë§¤í•‘\n",
    "train['íˆ¬ìë‹¨ê³„'] = train['íˆ¬ìë‹¨ê³„'].map(investment_stage_map)\n",
    "test['íˆ¬ìë‹¨ê³„'] = test['íˆ¬ìë‹¨ê³„'].map(investment_stage_map)\n",
    "\n",
    "# ê¸°ì—…ê°€ì¹˜ ë³€í™˜\n",
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(clean_valuation)\n",
    "test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(clean_valuation)\n",
    "\n",
    "# LabelEncoder ê°ì²´ë¥¼ ê° ë²”ì£¼í˜• featureë³„ë¡œ ë”°ë¡œ ì €ì¥í•˜ì—¬ ì‚¬ìš©\n",
    "encoders = {}\n",
    "\n",
    "# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ encoding\n",
    "for feature in category_features:\n",
    "    encoders[feature] = LabelEncoder()\n",
    "    train[feature] = train[feature].fillna('Missing')\n",
    "    test[feature] = test[feature].fillna('Missing')\n",
    "    train[feature] = encoders[feature].fit_transform(train[feature])\n",
    "    test[feature] = encoders[feature].transform(test[feature])\n",
    "\n",
    "# ë¶ˆë¦¬ì–¸ ê°’ì„ 0ê³¼ 1ë¡œ ë³€í™˜ ('Yes' â†’ 1, 'No' â†’ 0 ìœ¼ë¡œ ë³€í™˜)\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "\n",
    "for feature in bool_features:\n",
    "    train[feature] = train[feature].map(bool_map)\n",
    "    test[feature] = test[feature].map(bool_map)\n",
    "\n",
    "# # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ë¥¼ ì¤‘ê°„ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "# for feature in numeric_features:\n",
    "#     median_value = train[feature].median()\n",
    "#     train[feature] = train[feature].fillna(median_value)\n",
    "#     test[feature] = test[feature].fillna(median_value)\n",
    "\n",
    "# TabNetìš© ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ë±ìŠ¤(cat_idxs) ë° ì°¨ì›(cat_dims) ì„¤ì •\n",
    "features = [col for col in train.columns if col != 'ì„±ê³µí™•ë¥ ']\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [train[col].max() + 1 for col in category_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ğŸ“Œ ì„¤ë¦½ì—°ë„ â†’ ì—°ì°¨\n",
    "current_year = 2025\n",
    "train['ì—°ì°¨'] = current_year - train['ì„¤ë¦½ì—°ë„']\n",
    "test['ì—°ì°¨'] = current_year - test['ì„¤ë¦½ì—°ë„']\n",
    "train.drop(columns=['ì„¤ë¦½ì—°ë„'], inplace=True)\n",
    "test.drop(columns=['ì„¤ë¦½ì—°ë„'], inplace=True)\n",
    "\n",
    "# âœ… ì „ì²˜ë¦¬ ëŒ€ìƒ ì»¬ëŸ¼ ë¶„ë¥˜\n",
    "category_features = ['êµ­ê°€', 'ë¶„ì•¼']\n",
    "numeric_features = ['ì—°ì°¨', 'íˆ¬ìë‹¨ê³„', 'ì§ì› ìˆ˜', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "bool_features = ['ì¸ìˆ˜ì—¬ë¶€', 'ìƒì¥ì—¬ë¶€']\n",
    "\n",
    "# âœ… íˆ¬ìë‹¨ê³„ ë¬¸ìì—´ â†’ ìˆ«ì ë§µí•‘\n",
    "investment_stage_map = {\n",
    "    'Seed': 0.546171,\n",
    "    'Series A':  0.538014,\n",
    "    'Series B': 0.527797,\n",
    "    'Series C': 0.538425,\n",
    "    'IPO': 0.536141\n",
    "}\n",
    "\n",
    "train['íˆ¬ìë‹¨ê³„'] = train['íˆ¬ìë‹¨ê³„'].map(investment_stage_map)\n",
    "test['íˆ¬ìë‹¨ê³„'] = test['íˆ¬ìë‹¨ê³„'].map(investment_stage_map)\n",
    "\n",
    "# âœ… ê¸°ì—…ê°€ì¹˜ ë¬¸ìì—´ ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©\n",
    "train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = train['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(clean_valuation)\n",
    "test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = test['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].apply(clean_valuation)\n",
    "\n",
    "# âœ… íƒ€ê²Ÿ ì¸ì½”ë”© í‰ê· ê°’ ë”•ì…”ë„ˆë¦¬\n",
    "avg_success_dict = {\n",
    "    'êµ­ê°€': {\n",
    "        'CT009': 0.556098,\n",
    "        'CT008': 0.549775,\n",
    "        'CT006': 0.548276,\n",
    "        'CT007': 0.540094,\n",
    "        'CT005': 0.537220,\n",
    "        'CT003': 0.535022,\n",
    "        'CT010': 0.533333,\n",
    "        'CT001': 0.531303,\n",
    "        'CT004': 0.529274,\n",
    "        'CT002': 0.515367\n",
    "    },\n",
    "    'ë¶„ì•¼': {\n",
    "        'í•€í…Œí¬': 0.567151,\n",
    "        'ê¸°ìˆ ': 0.540103,\n",
    "        'ë¬¼ë¥˜': 0.539939,\n",
    "        'ì—ë“€í…Œí¬': 0.539011,\n",
    "        'AI': 0.537079,\n",
    "        'í‘¸ë“œí…Œí¬': 0.533731,\n",
    "        'ê²Œì„': 0.532869,\n",
    "        'ì—ë„ˆì§€': 0.529545,\n",
    "        'ì´ì»¤ë¨¸ìŠ¤': 0.520482,\n",
    "        'í—¬ìŠ¤ì¼€ì–´': 0.493671\n",
    "    },\n",
    "    'ì¸ìˆ˜ì—¬ë¶€': {\n",
    "        'No': 0.540349,\n",
    "        'Yes': 0.534515\n",
    "    },\n",
    "    'ìƒì¥ì—¬ë¶€': {\n",
    "        'Yes': 0.545196,\n",
    "        'No': 0.530004\n",
    "    }\n",
    "}\n",
    "\n",
    "# âœ… í•´ë‹¹ ì»¬ëŸ¼ íƒ€ê²Ÿ ì¸ì½”ë”© ì ìš©\n",
    "for col in ['êµ­ê°€', 'ë¶„ì•¼', 'ì¸ìˆ˜ì—¬ë¶€', 'ìƒì¥ì—¬ë¶€']:\n",
    "    train[col] = train[col].map(avg_success_dict[col])\n",
    "    test[col] = test[col].map(avg_success_dict[col])\n",
    "\n",
    "# âœ… ë¶ˆë¦¬ì–¸ í˜•íƒœê°€ ì•„ì§ ë¬¸ìì—´ì´ë©´ ë³€í™˜ (ë³´ì™„ìš©, ì´ë¯¸ ìˆ«ìë©´ ì˜í–¥ ì—†ìŒ)\n",
    "# bool_map = {'Yes': 1, 'No': 0}\n",
    "# for feature in bool_features:\n",
    "#     train[feature] = train[feature].map(bool_map).fillna(train[feature])\n",
    "#     test[feature] = test[feature].map(bool_map).fillna(test[feature])\n",
    "\n",
    "# âœ… (ì„ íƒ) ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ëŠ” ì¤‘ê°„ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "# for feature in numeric_features:\n",
    "#     median_value = train[feature].median()\n",
    "#     train[feature] = train[feature].fillna(median_value)\n",
    "#     test[feature] = test[feature].fillna(median_value)\n",
    "\n",
    "# âœ… feature ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì„±ê³µí™•ë¥  ì œì™¸)\n",
    "features = [col for col in train.columns if col != 'ì„±ê³µí™•ë¥ ']\n",
    "\n",
    "# âœ… TabNetìš© cat_idxs, cat_dims (ì´ ê²½ìš°ì—” íƒ€ê²Ÿ ì¸ì½”ë”©ìœ¼ë¡œ ëª¨ë‘ ìˆ˜ì¹˜í™” â†’ cat_idxs ë¹„ìš¸ ìˆ˜ ìˆìŒ)\n",
    "cat_idxs = []\n",
    "cat_dims = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    # 1ì¸ë‹¹ ì§€í‘œ\n",
    "    df['íˆ¬ì_ì§ì›ìˆ˜'] = df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / df['ì§ì› ìˆ˜']\n",
    "    df['ë§¤ì¶œ_ì§ì›ìˆ˜'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / df['ì§ì› ìˆ˜']\n",
    "\n",
    "    # ë¹„ìœ¨ ì§€í‘œ\n",
    "    df['ë§¤ì¶œ_íˆ¬ì'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / df['ì´ íˆ¬ìê¸ˆ(ì–µì›)']\n",
    "    df['íˆ¬ì_ê¸°ì—…ê°€ì¹˜'] = df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "    df['ë§¤ì¶œ_ê³ ê°'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)']\n",
    "\n",
    "    # ìŠ¤ì¼€ì¼ ë³€í™˜\n",
    "    df['ì—°ì°¨_ë£¨íŠ¸'] = np.sqrt(df['ì—°ì°¨'])\n",
    "\n",
    "    # ì¶”ê°€ íŒŒìƒ í”¼ì²˜\n",
    "    df['ê¸°ì—…ê°€ì¹˜_íˆ¬ì'] = df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] / df['ì´ íˆ¬ìê¸ˆ(ì–µì›)']\n",
    "    df['íŒ”ë¡œì›Œ_ê³ ê°'] = df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] / df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)']\n",
    "    df['íŒ”ë¡œì›Œ_ê¸°ì—…ê°€ì¹˜'] = df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] / df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "    df['ê³ ê°_ì§ì›ìˆ˜'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / df['ì§ì› ìˆ˜']\n",
    "    df['ë§¤ì¶œ_ê¸°ì—…ê°€ì¹˜'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']\n",
    "    df['ë§¤ì¶œ_ì—°ì°¨'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / df['ì—°ì°¨']\n",
    "    df['ë§¤ì¶œ_íŒ”ë¡œì›Œ'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_stat_score(df, avg_dict):\n",
    "    score = pd.Series(1.0, index=df.index)  # ì´ˆê¸°ê°’: ê³±ì…ˆ ë‹¨ìœ„ 1.0\n",
    "    for col in avg_dict:\n",
    "        mapped = df[col].map(avg_dict[col])\n",
    "        \n",
    "        # ë§¤í•‘ ì•ˆ ë˜ëŠ” ê°’ ìˆì„ ê²½ìš° í™•ì¸ìš© ë¡œê·¸ ì¶œë ¥ (ë˜ëŠ” raise ì—ëŸ¬ ì²˜ë¦¬ ê°€ëŠ¥)\n",
    "        if mapped.isna().any():\n",
    "            missing_vals = df.loc[mapped.isna(), col].unique()\n",
    "            raise ValueError(f\"[{col}]ì— ë§¤í•‘ë˜ì§€ ì•Šì€ ê°’ ì¡´ì¬: {missing_vals}\")\n",
    "        \n",
    "        score += mapped\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_dictëŠ” ì´ë¯¸ ì¤€ë¹„ëœ ìƒíƒœë¼ê³  ê°€ì •\n",
    "avg_dict = {\n",
    "    'ìƒì¥ì—¬ë¶€': {1: 0.545196, 0: 0.530004},\n",
    "    'ì¸ìˆ˜ì—¬ë¶€': {0: 0.540349, 1: 0.534515},\n",
    "    'êµ­ê°€': {\n",
    "        8: 0.556098, 7: 0.549775, 5: 0.548276, 6: 0.540094, 4: 0.537220,\n",
    "        2: 0.535022, 9: 0.533333, 0: 0.531303, 3: 0.529274, 1: 0.515367\n",
    "    },\n",
    "    'ë¶„ì•¼': {\n",
    "        9: 0.567151, 1: 0.552042, 3: 0.540103, 4: 0.539939, 6: 0.539011,\n",
    "        0: 0.537079, 8: 0.533731, 2: 0.532869, 5: 0.529545, 7: 0.520482, 10: 0.493671\n",
    "    },\n",
    "    'íˆ¬ìë‹¨ê³„': {\n",
    "        0: 0.546171, 3: 0.538425, 1: 0.538014, 4: 0.536141, 2: 0.527797\n",
    "    }\n",
    "}\n",
    "\n",
    "train['í†µí•©ì„±ê³µìŠ¤ì½”ì–´'] = compute_combined_stat_score(train, avg_dict)\n",
    "test['í†µí•©ì„±ê³µìŠ¤ì½”ì–´'] = compute_combined_stat_score(test, avg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [\n",
    "    'ì—°ì°¨'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [\n",
    "    'íˆ¬ì_ì§ì›ìˆ˜', 'ë§¤ì¶œ_ì§ì›ìˆ˜', 'ë§¤ì¶œ_íˆ¬ì',\n",
    "    'íˆ¬ì_ê¸°ì—…ê°€ì¹˜', 'ë§¤ì¶œ_ê³ ê°', 'ì—°ì°¨_ë£¨íŠ¸',\n",
    "    'ê¸°ì—…ê°€ì¹˜_íˆ¬ì', 'íŒ”ë¡œì›Œ_ê³ ê°', 'íŒ”ë¡œì›Œ_ê¸°ì—…ê°€ì¹˜',\n",
    "    'ê³ ê°_ì§ì›ìˆ˜', 'ë§¤ì¶œ_ê¸°ì—…ê°€ì¹˜', 'ë§¤ì¶œ_ì—°ì°¨',\n",
    "    'ë§¤ì¶œ_íŒ”ë¡œì›Œ'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°\n",
    "features = [f for f in features if f not in ['êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ì¸ìˆ˜ì—¬ë¶€', 'ìƒì¥ì—¬ë¶€', 'ì§ì› ìˆ˜', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°\n",
    "features = [f for f in features if f not in ['í†µí•©ì„±ê³µìŠ¤ì½”ì–´']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ìƒì¥ì—¬ë¶€</th>\n",
       "      <th>êµ­ê°€</th>\n",
       "      <th>ë¶„ì•¼</th>\n",
       "      <th>íˆ¬ìë‹¨ê³„</th>\n",
       "      <th>ì¸ìˆ˜ì—¬ë¶€</th>\n",
       "      <th>ì„±ê³µí™•ë¥ </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ìƒì¥ì—¬ë¶€  êµ­ê°€  ë¶„ì•¼  íˆ¬ìë‹¨ê³„  ì¸ìˆ˜ì—¬ë¶€  ì„±ê³µí™•ë¥ \n",
       "793      0   8   7     4     0   0.9\n",
       "495      0   5   3     4     0   0.9\n",
       "1687     1   8   6     4     1   0.9\n",
       "1628     1   7  10     4     0   0.9\n",
       "1627     1   7  10     3     0   0.9\n",
       "...    ...  ..  ..   ...   ...   ...\n",
       "1388     1   5   2     1     0   0.1\n",
       "1600     1   7   7     1     0   0.1\n",
       "1387     1   5   2     0     1   0.1\n",
       "207      0   2   2     4     1   0.1\n",
       "514      0   5   6     1     1   0.1\n",
       "\n",
       "[1810 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_cols = ['ìƒì¥ì—¬ë¶€', 'êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ì¸ìˆ˜ì—¬ë¶€']\n",
    "success_rate_mean = train.groupby(group_cols)['ì„±ê³µí™•ë¥ '].mean().reset_index()\n",
    "\n",
    "# ë³´ê¸° ì‰½ê²Œ ì •ë ¬\n",
    "success_rate_mean = success_rate_mean.sort_values(by='ì„±ê³µí™•ë¥ ', ascending=False)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "display(success_rate_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìƒì¥ì—¬ë¶€ë³„ ì„±ê³µí™•ë¥  í‰ê· \n",
      "ìƒì¥ì—¬ë¶€\n",
      "Yes    0.545196\n",
      "No     0.530004\n",
      "Name: ì„±ê³µí™•ë¥ , dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… ìƒì¥ì—¬ë¶€ë³„ ì„±ê³µí™•ë¥  í‰ê· \")\n",
    "print(train.groupby('ìƒì¥ì—¬ë¶€')['ì„±ê³µí™•ë¥ '].mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… êµ­ê°€ë³„ ì„±ê³µí™•ë¥  í‰ê· \n",
      "êµ­ê°€\n",
      "CT009    0.556098\n",
      "CT008    0.549775\n",
      "CT006    0.548276\n",
      "CT007    0.540094\n",
      "CT005    0.537220\n",
      "CT003    0.535022\n",
      "CT010    0.533333\n",
      "CT001    0.531303\n",
      "CT004    0.529274\n",
      "CT002    0.515367\n",
      "Name: ì„±ê³µí™•ë¥ , dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… êµ­ê°€ë³„ ì„±ê³µí™•ë¥  í‰ê· \")\n",
    "print(train.groupby('êµ­ê°€')['ì„±ê³µí™•ë¥ '].mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë¶„ì•¼ë³„ ì„±ê³µí™•ë¥  í‰ê· \n",
      "ë¶„ì•¼\n",
      "í•€í…Œí¬     0.567151\n",
      "ê¸°ìˆ       0.540103\n",
      "ë¬¼ë¥˜      0.539939\n",
      "ì—ë“€í…Œí¬    0.539011\n",
      "AI      0.537079\n",
      "í‘¸ë“œí…Œí¬    0.533731\n",
      "ê²Œì„      0.532869\n",
      "ì—ë„ˆì§€     0.529545\n",
      "ì´ì»¤ë¨¸ìŠ¤    0.520482\n",
      "í—¬ìŠ¤ì¼€ì–´    0.493671\n",
      "Name: ì„±ê³µí™•ë¥ , dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… ë¶„ì•¼ë³„ ì„±ê³µí™•ë¥  í‰ê· \")\n",
    "print(train.groupby('ë¶„ì•¼')['ì„±ê³µí™•ë¥ '].mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì¸ìˆ˜ì—¬ë¶€ë³„ ì„±ê³µí™•ë¥  í‰ê· \n",
      "ì¸ìˆ˜ì—¬ë¶€\n",
      "No     0.540349\n",
      "Yes    0.534515\n",
      "Name: ì„±ê³µí™•ë¥ , dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… ì¸ìˆ˜ì—¬ë¶€ë³„ ì„±ê³µí™•ë¥  í‰ê· \")\n",
    "print(train.groupby('ì¸ìˆ˜ì—¬ë¶€')['ì„±ê³µí™•ë¥ '].mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… íˆ¬ìë‹¨ê³„ë³„ ì„±ê³µí™•ë¥  í‰ê· \n",
      "íˆ¬ìë‹¨ê³„\n",
      "0    0.546171\n",
      "3    0.538425\n",
      "1    0.538014\n",
      "4    0.536141\n",
      "2    0.527797\n",
      "Name: ì„±ê³µí™•ë¥ , dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… íˆ¬ìë‹¨ê³„ë³„ ì„±ê³µí™•ë¥  í‰ê· \")\n",
    "print(train.groupby('íˆ¬ìë‹¨ê³„')['ì„±ê³µí™•ë¥ '].mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê· ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥\n",
    "êµ­ê°€ë³„_ì—°ë§¤ì¶œ_í‰ê· _dict = train.groupby('êµ­ê°€')['ì—°ë§¤ì¶œ(ì–µì›)'].mean().to_dict()\n",
    "ë¶„ì•¼ë³„_ê³ ê°ìˆ˜_í‰ê· _dict = train.groupby('ë¶„ì•¼')['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].mean().to_dict()\n",
    "\n",
    "for df in [train, test]:\n",
    "    êµ­ê°€_í‰ê·  = df['êµ­ê°€'].map(êµ­ê°€ë³„_ì—°ë§¤ì¶œ_í‰ê· _dict)\n",
    "    ë¶„ì•¼_í‰ê·  = df['ë¶„ì•¼'].map(ë¶„ì•¼ë³„_ê³ ê°ìˆ˜_í‰ê· _dict)\n",
    "\n",
    "    # ë¶„ëª¨ì— 1e6 ë”í•¨\n",
    "    df['ì—°ë§¤ì¶œ_êµ­ê°€í‰ê· _ë¹„ìœ¨'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (êµ­ê°€_í‰ê·  + 1e6)\n",
    "    df['ê³ ê°ìˆ˜_ë¶„ì•¼í‰ê· _ë¹„ìœ¨'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / (ë¶„ì•¼_í‰ê·  + 1e6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [\n",
    "    'ì—°ë§¤ì¶œ_êµ­ê°€í‰ê· _ë¹„ìœ¨', 'ê³ ê°ìˆ˜_ë¶„ì•¼í‰ê· _ë¹„ìœ¨'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['ë§¤ì¶œ_ì´íˆ¬ìë¹„ìœ¨'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1)\n",
    "    df['ê¸°ì—…ê°€ì¹˜_ì§ì›ìˆ˜'] = df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] / (df['ì§ì› ìˆ˜'] + 1)\n",
    "    df['íˆ¬ì_per_ì—°ì°¨'] = df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / (df['ì—°ì°¨'] + 1)\n",
    "    df['ê³ ê°ìˆ˜_per_ì—°ì°¨'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / (df['ì—°ì°¨'] + 1)\n",
    "    df['ë§¤ì¶œ_per_ê³ ê°_per_ì§ì›'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] * df['ì§ì› ìˆ˜'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [\n",
    "    'ë§¤ì¶œ_ì´íˆ¬ìë¹„ìœ¨', 'ê¸°ì—…ê°€ì¹˜_ì§ì›ìˆ˜', 'íˆ¬ì_per_ì—°ì°¨', 'ê³ ê°ìˆ˜_per_ì—°ì°¨', 'ë§¤ì¶œ_per_ê³ ê°_per_ì§ì›'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ê³ ê°ìˆ˜(ë°±ë§Œëª…)',\n",
       " 'ì´ íˆ¬ìê¸ˆ(ì–µì›)',\n",
       " 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)',\n",
       " 'ì—°ì°¨',\n",
       " 'íˆ¬ì_ì§ì›ìˆ˜',\n",
       " 'ë§¤ì¶œ_ì§ì›ìˆ˜',\n",
       " 'ë§¤ì¶œ_íˆ¬ì',\n",
       " 'íˆ¬ì_ê¸°ì—…ê°€ì¹˜',\n",
       " 'ë§¤ì¶œ_ê³ ê°',\n",
       " 'ì—°ì°¨_ë£¨íŠ¸',\n",
       " 'ê¸°ì—…ê°€ì¹˜_íˆ¬ì',\n",
       " 'íŒ”ë¡œì›Œ_ê³ ê°',\n",
       " 'íŒ”ë¡œì›Œ_ê¸°ì—…ê°€ì¹˜',\n",
       " 'ê³ ê°_ì§ì›ìˆ˜',\n",
       " 'ë§¤ì¶œ_ê¸°ì—…ê°€ì¹˜',\n",
       " 'ë§¤ì¶œ_ì—°ì°¨',\n",
       " 'ë§¤ì¶œ_íŒ”ë¡œì›Œ',\n",
       " 'ì—°ë§¤ì¶œ_êµ­ê°€í‰ê· _ë¹„ìœ¨',\n",
       " 'ê³ ê°ìˆ˜_ë¶„ì•¼í‰ê· _ë¹„ìœ¨']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì—°ë§¤ì¶œ ì œê±° íš¨ê³¼ ìˆìŒ /\n",
    "## ì—°ì°¨_ë£¨íŠ¸, ê¸°ì—…ê°€ì¹˜, íˆ¬ìê¸ˆ, ë§¤ì¶œ_ê¸°ì—…ê°€ì¹˜, ë§¤ì¶œ_íˆ¬ì ì œê±° íš¨ê³¼ ì—†ìŒ\n",
    "## // ì¤‘ê°„ : ê³ ê°ìˆ˜(ë°±ë§Œëª…)\n",
    "## // ë§¤ì¶œ_ê¸°ì—…ê°€ì¹˜, ì—°ì°¨ ê·¸ëŒ€ë¡œì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in features if f not in ['ì—°ë§¤ì¶œ(ì–µì›)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in features if f not in ['ë§¤ì¶œ_ì´íˆ¬ìë¹„ìœ¨', 'ê¸°ì—…ê°€ì¹˜_ì§ì›ìˆ˜', 'íˆ¬ì_per_ì—°ì°¨', 'ê³ ê°ìˆ˜_per_ì—°ì°¨', 'ë§¤ì¶œ_per_ê³ ê°_per_ì§ì›']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [\n",
    "    'íˆ¬ì_ì§ì›ìˆ˜'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:10:31,816] A new study created in memory with name: no-name-2d182a0f-0ad0-4e6c-b587-6e0d5e8ef573\n",
      "[I 2025-04-16 23:10:35,847] Trial 0 finished with value: 0.19551063411312017 and parameters: {'subsample': 0.8200000000000001, 'colsample_bytree': 0.74}. Best is trial 0 with value: 0.19551063411312017.\n",
      "[I 2025-04-16 23:10:40,622] Trial 1 finished with value: 0.19454891444545358 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.78}. Best is trial 1 with value: 0.19454891444545358.\n",
      "[I 2025-04-16 23:10:44,653] Trial 2 finished with value: 0.19468286883885458 and parameters: {'subsample': 0.98, 'colsample_bytree': 0.72}. Best is trial 1 with value: 0.19454891444545358.\n",
      "[I 2025-04-16 23:10:47,178] Trial 3 finished with value: 0.19480198572079344 and parameters: {'subsample': 1.0, 'colsample_bytree': 0.66}. Best is trial 1 with value: 0.19454891444545358.\n",
      "[I 2025-04-16 23:10:51,670] Trial 4 finished with value: 0.19553580454903652 and parameters: {'subsample': 0.9400000000000001, 'colsample_bytree': 0.78}. Best is trial 1 with value: 0.19454891444545358.\n",
      "[I 2025-04-16 23:10:56,851] Trial 5 finished with value: 0.19462159138904314 and parameters: {'subsample': 1.0, 'colsample_bytree': 0.52}. Best is trial 1 with value: 0.19454891444545358.\n",
      "[I 2025-04-16 23:11:00,887] Trial 6 finished with value: 0.19500271261554875 and parameters: {'subsample': 0.8, 'colsample_bytree': 0.74}. Best is trial 1 with value: 0.19454891444545358.\n",
      "[I 2025-04-16 23:11:05,675] Trial 7 finished with value: 0.1941842064737729 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.56}. Best is trial 7 with value: 0.1941842064737729.\n",
      "[I 2025-04-16 23:11:11,204] Trial 8 finished with value: 0.19443530271246554 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.78}. Best is trial 7 with value: 0.1941842064737729.\n",
      "[I 2025-04-16 23:11:14,956] Trial 9 finished with value: 0.1946990906477791 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 7 with value: 0.1941842064737729.\n",
      "[I 2025-04-16 23:11:20,013] Trial 10 finished with value: 0.19580878713699781 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.96}. Best is trial 7 with value: 0.1941842064737729.\n",
      "[I 2025-04-16 23:11:25,437] Trial 11 finished with value: 0.19414535185926035 and parameters: {'subsample': 0.9400000000000001, 'colsample_bytree': 0.5}. Best is trial 11 with value: 0.19414535185926035.\n",
      "[I 2025-04-16 23:11:30,633] Trial 12 finished with value: 0.1941632023617013 and parameters: {'subsample': 0.9600000000000001, 'colsample_bytree': 0.5}. Best is trial 11 with value: 0.19414535185926035.\n",
      "[I 2025-04-16 23:11:35,620] Trial 13 finished with value: 0.19425118194391192 and parameters: {'subsample': 0.9600000000000001, 'colsample_bytree': 0.6}. Best is trial 11 with value: 0.19414535185926035.\n",
      "[I 2025-04-16 23:11:40,844] Trial 14 finished with value: 0.1941632023617013 and parameters: {'subsample': 0.9600000000000001, 'colsample_bytree': 0.5}. Best is trial 11 with value: 0.19414535185926035.\n",
      "[I 2025-04-16 23:11:45,851] Trial 15 finished with value: 0.19395626679266967 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.62}. Best is trial 15 with value: 0.19395626679266967.\n",
      "[I 2025-04-16 23:11:50,891] Trial 16 finished with value: 0.19395626679266967 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.62}. Best is trial 15 with value: 0.19395626679266967.\n",
      "[I 2025-04-16 23:11:57,463] Trial 17 finished with value: 0.19356258757854705 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.64}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:02,730] Trial 18 finished with value: 0.1944762864613642 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.86}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:09,088] Trial 19 finished with value: 0.1938532644312948 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.6799999999999999}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:13,954] Trial 20 finished with value: 0.19513043054979143 and parameters: {'subsample': 0.8200000000000001, 'colsample_bytree': 0.66}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:20,178] Trial 21 finished with value: 0.1938532644312948 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.6799999999999999}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:26,463] Trial 22 finished with value: 0.1938532644312948 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.6799999999999999}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:30,776] Trial 23 finished with value: 0.194761525720494 and parameters: {'subsample': 0.88, 'colsample_bytree': 0.7}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:35,212] Trial 24 finished with value: 0.19462951760245786 and parameters: {'subsample': 0.8200000000000001, 'colsample_bytree': 0.86}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:37,671] Trial 25 finished with value: 0.1956346644454351 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.58}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:42,373] Trial 26 finished with value: 0.19495562172439548 and parameters: {'subsample': 0.8, 'colsample_bytree': 0.64}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:48,646] Trial 27 finished with value: 0.19504752838856554 and parameters: {'subsample': 0.88, 'colsample_bytree': 0.56}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:53,302] Trial 28 finished with value: 0.1949013478985932 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.7}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:12:59,526] Trial 29 finished with value: 0.1950430995355186 and parameters: {'subsample': 0.88, 'colsample_bytree': 0.86}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:04,316] Trial 30 finished with value: 0.19462777772518597 and parameters: {'subsample': 0.8200000000000001, 'colsample_bytree': 0.8200000000000001}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:10,674] Trial 31 finished with value: 0.1938532644312948 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.6799999999999999}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:15,094] Trial 32 finished with value: 0.19452541779777774 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.74}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:19,916] Trial 33 finished with value: 0.19495562172439548 and parameters: {'subsample': 0.8, 'colsample_bytree': 0.6799999999999999}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:24,723] Trial 34 finished with value: 0.1949013478985932 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.72}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:29,636] Trial 35 finished with value: 0.19513043054979143 and parameters: {'subsample': 0.8200000000000001, 'colsample_bytree': 0.66}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:35,972] Trial 36 finished with value: 0.19575343088132063 and parameters: {'subsample': 0.88, 'colsample_bytree': 0.62}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:40,924] Trial 37 finished with value: 0.19401782836816084 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.76}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:45,637] Trial 38 finished with value: 0.1949013478985932 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.7}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:51,865] Trial 39 finished with value: 0.194167196458061 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.54}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:13:56,338] Trial 40 finished with value: 0.19530516591042146 and parameters: {'subsample': 0.8, 'colsample_bytree': 0.58}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:14:02,682] Trial 41 finished with value: 0.1938532644312948 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.6799999999999999}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:14:07,590] Trial 42 finished with value: 0.19513043054979143 and parameters: {'subsample': 0.8200000000000001, 'colsample_bytree': 0.64}. Best is trial 17 with value: 0.19356258757854705.\n",
      "[I 2025-04-16 23:14:14,020] Trial 43 finished with value: 0.19355571266246713 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.72}. Best is trial 43 with value: 0.19355571266246713.\n",
      "[I 2025-04-16 23:14:19,065] Trial 44 finished with value: 0.19401782836816084 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 0.74}. Best is trial 43 with value: 0.19355571266246713.\n",
      "[I 2025-04-16 23:14:23,498] Trial 45 finished with value: 0.194761525720494 and parameters: {'subsample': 0.88, 'colsample_bytree': 0.72}. Best is trial 43 with value: 0.19355571266246713.\n",
      "[I 2025-04-16 23:14:28,331] Trial 46 finished with value: 0.19467578763354856 and parameters: {'subsample': 0.8600000000000001, 'colsample_bytree': 1.0}. Best is trial 43 with value: 0.19355571266246713.\n",
      "[I 2025-04-16 23:14:33,599] Trial 47 finished with value: 0.19454891444545358 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.76}. Best is trial 43 with value: 0.19355571266246713.\n",
      "[I 2025-04-16 23:14:38,541] Trial 48 finished with value: 0.19396292534933243 and parameters: {'subsample': 0.8400000000000001, 'colsample_bytree': 0.8}. Best is trial 43 with value: 0.19355571266246713.\n",
      "[I 2025-04-16 23:14:43,786] Trial 49 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:14:49,162] Trial 50 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:14:54,338] Trial 51 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:14:59,605] Trial 52 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:03,986] Trial 53 finished with value: 0.19433355027273908 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.6}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:08,327] Trial 54 finished with value: 0.19502573397061596 and parameters: {'subsample': 0.9400000000000001, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:12,755] Trial 55 finished with value: 0.19433355027273908 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.62}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:18,298] Trial 56 finished with value: 0.19450801363614598 and parameters: {'subsample': 0.9400000000000001, 'colsample_bytree': 0.6}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:23,712] Trial 57 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.66}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:28,226] Trial 58 finished with value: 0.19502573397061596 and parameters: {'subsample': 0.9400000000000001, 'colsample_bytree': 0.66}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:34,169] Trial 59 finished with value: 0.19471199119540109 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.58}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:39,149] Trial 60 finished with value: 0.1941842064737729 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.54}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:44,509] Trial 61 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:49,907] Trial 62 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.66}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:54,176] Trial 63 finished with value: 0.19433355027273908 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.62}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:15:59,574] Trial 64 finished with value: 0.1930606259670976 and parameters: {'subsample': 0.92, 'colsample_bytree': 0.64}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:16:05,185] Trial 65 finished with value: 0.19450801363614598 and parameters: {'subsample': 0.9400000000000001, 'colsample_bytree': 0.6}. Best is trial 49 with value: 0.1930606259670976.\n",
      "[I 2025-04-16 23:16:10,506] Trial 66 finished with value: 0.19301115587081538 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.66}. Best is trial 66 with value: 0.19301115587081538.\n",
      "[I 2025-04-16 23:16:15,959] Trial 67 finished with value: 0.1937569216472101 and parameters: {'subsample': 0.9600000000000001, 'colsample_bytree': 0.56}. Best is trial 66 with value: 0.19301115587081538.\n",
      "[I 2025-04-16 23:16:21,654] Trial 68 finished with value: 0.19422674859155256 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.7}. Best is trial 66 with value: 0.19301115587081538.\n",
      "[I 2025-04-16 23:16:26,926] Trial 69 finished with value: 0.19301115587081538 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.66}. Best is trial 66 with value: 0.19301115587081538.\n",
      "[I 2025-04-16 23:16:32,237] Trial 70 finished with value: 0.19301115587081538 and parameters: {'subsample': 0.9, 'colsample_bytree': 0.66}. Best is trial 66 with value: 0.19301115587081538.\n",
      "[W 2025-04-16 23:16:35,402] Trial 71 failed with parameters: {'subsample': 0.9, 'colsample_bytree': 0.66} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyun/torch_venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/jb/yg6x_wxn2fb7rpvjf55n9b5c0000gn/T/ipykernel_70088/1398457689.py\", line 30, in objective\n",
      "    model = xgb.train(\n",
      "            ^^^^^^^^^^\n",
      "  File \"/Users/hyun/torch_venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/hyun/torch_venv/lib/python3.12/site-packages/xgboost/training.py\", line 183, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/Users/hyun/torch_venv/lib/python3.12/site-packages/xgboost/core.py\", line 2247, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-16 23:16:35,403] Trial 71 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 2. study ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m     44\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# MAE ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ì›í•˜ëŠ” ë§Œí¼ ì‹œë„\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 3. ê²°ê³¼ í™•ì¸\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Best trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[45], line 30\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[1;32m     17\u001b[0m     param \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     28\u001b[0m     }\n\u001b[0;32m---> 30\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dvalid)\n\u001b[1;32m     40\u001b[0m     score \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_valid, preds)\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/xgboost/training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/torch_venv/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2246\u001b[0m     _check_call(\n\u001b[0;32m-> 2247\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2250\u001b[0m     )\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ë°ì´í„° ë¶„ë¦¬ (optunaëŠ” foldë³´ë‹¤ ë¹ ë¥¸ ì‹¤í—˜ì— ì í•©)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    train[features], train['ì„±ê³µí™•ë¥ '], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# DMatrix ë³€í™˜\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# 1. objective í•¨ìˆ˜ ì •ì˜\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'mae',\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 19,\n",
    "        'subsample': trial.suggest_float('subsample', 0.8, 1, step=0.02),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1, step=0.02),\n",
    "        'lambda': 0,\n",
    "        'alpha': 0,\n",
    "        'tree_method': 'hist',\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=param,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(dvalid, 'valid')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dvalid)\n",
    "    score = mean_absolute_error(y_valid, preds)\n",
    "    return score  # MAEê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ!\n",
    "\n",
    "# 2. study ì‹¤í–‰\n",
    "study = optuna.create_study(direction='minimize')  # MAE ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
    "study.optimize(objective, n_trials=300)  # ì›í•˜ëŠ” ë§Œí¼ ì‹œë„\n",
    "\n",
    "# 3. ê²°ê³¼ í™•ì¸\n",
    "print(\"âœ… Best trial:\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë² ìŠ¤íŠ¸2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    'learning_rate': 0.01999442928330417,\n",
    "    'max_depth': 19,\n",
    "    'subsample': 0.9480568751181326,\n",
    "    'colsample_bytree': 0.754082682926498,\n",
    "    'lambda': 0.00160708810021216,\n",
    "    'alpha': 0.003025787373246697,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'learning_rate': 0.015,\n",
    "    'max_depth': 18,\n",
    "    'subsample': 0.9480568751181326,\n",
    "    'colsample_bytree': 0.754082682926498,\n",
    "    'lambda': 0.00160708810021216,\n",
    "    'alpha': 0,\n",
    "    'tree_method': 'hist',\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    'learning_rate': 0.015,\n",
    "    'max_depth': 18,\n",
    "    'subsample': 0.65,\n",
    "    'colsample_bytree': 0.57,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    'learning_rate': 0.015,\n",
    "    'max_depth': 18,\n",
    "    'subsample': 0.80,\n",
    "    'colsample_bytree': 0.79,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    'learning_rate': 0.015,\n",
    "    'max_depth': 18,\n",
    "    'subsample': 0.95,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    'learning_rate': 0.015,\n",
    "    'max_depth': 18,\n",
    "    'subsample': 0.77,\n",
    "    'colsample_bytree': 0.94,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 19,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Fold 1/10\n",
      "[0]\ttrain-mae:0.20365\tvalid-mae:0.20036\n",
      "[100]\ttrain-mae:0.08588\tvalid-mae:0.19258\n",
      "[200]\ttrain-mae:0.03620\tvalid-mae:0.19109\n",
      "[300]\ttrain-mae:0.01540\tvalid-mae:0.19044\n",
      "[400]\ttrain-mae:0.00677\tvalid-mae:0.19024\n",
      "[500]\ttrain-mae:0.00299\tvalid-mae:0.19023\n",
      "[600]\ttrain-mae:0.00136\tvalid-mae:0.19019\n",
      "[700]\ttrain-mae:0.00066\tvalid-mae:0.19018\n",
      "[800]\ttrain-mae:0.00052\tvalid-mae:0.19019\n",
      "[900]\ttrain-mae:0.00049\tvalid-mae:0.19019\n",
      "[1000]\ttrain-mae:0.00049\tvalid-mae:0.19019\n",
      "[1100]\ttrain-mae:0.00049\tvalid-mae:0.19019\n",
      "[1200]\ttrain-mae:0.00048\tvalid-mae:0.19019\n",
      "[1300]\ttrain-mae:0.00048\tvalid-mae:0.19019\n",
      "[1400]\ttrain-mae:0.00048\tvalid-mae:0.19019\n",
      "[1500]\ttrain-mae:0.00048\tvalid-mae:0.19019\n",
      "[1600]\ttrain-mae:0.00048\tvalid-mae:0.19019\n",
      "[1693]\ttrain-mae:0.00047\tvalid-mae:0.19019\n",
      "  ğŸ” Fold 1 MAE: 0.1902\n",
      "\n",
      "ğŸ” Fold 2/10\n",
      "[0]\ttrain-mae:0.20300\tvalid-mae:0.20997\n",
      "[100]\ttrain-mae:0.08604\tvalid-mae:0.19997\n",
      "[200]\ttrain-mae:0.03696\tvalid-mae:0.19687\n",
      "[300]\ttrain-mae:0.01588\tvalid-mae:0.19606\n",
      "[400]\ttrain-mae:0.00702\tvalid-mae:0.19577\n",
      "[500]\ttrain-mae:0.00313\tvalid-mae:0.19563\n",
      "[600]\ttrain-mae:0.00143\tvalid-mae:0.19561\n",
      "[700]\ttrain-mae:0.00069\tvalid-mae:0.19560\n",
      "[800]\ttrain-mae:0.00052\tvalid-mae:0.19560\n",
      "[900]\ttrain-mae:0.00051\tvalid-mae:0.19560\n",
      "[1000]\ttrain-mae:0.00050\tvalid-mae:0.19560\n",
      "[1100]\ttrain-mae:0.00050\tvalid-mae:0.19560\n",
      "[1200]\ttrain-mae:0.00049\tvalid-mae:0.19560\n",
      "[1300]\ttrain-mae:0.00049\tvalid-mae:0.19560\n",
      "[1400]\ttrain-mae:0.00049\tvalid-mae:0.19560\n",
      "[1500]\ttrain-mae:0.00048\tvalid-mae:0.19560\n",
      "[1600]\ttrain-mae:0.00048\tvalid-mae:0.19560\n",
      "[1700]\ttrain-mae:0.00048\tvalid-mae:0.19560\n",
      "[1800]\ttrain-mae:0.00048\tvalid-mae:0.19560\n",
      "[1900]\ttrain-mae:0.00048\tvalid-mae:0.19560\n",
      "[1999]\ttrain-mae:0.00048\tvalid-mae:0.19560\n",
      "  ğŸ” Fold 2 MAE: 0.1956\n",
      "\n",
      "ğŸ” Fold 3/10\n",
      "[0]\ttrain-mae:0.20253\tvalid-mae:0.21029\n",
      "[100]\ttrain-mae:0.08532\tvalid-mae:0.20494\n",
      "[200]\ttrain-mae:0.03654\tvalid-mae:0.20495\n",
      "[300]\ttrain-mae:0.01577\tvalid-mae:0.20489\n",
      "[400]\ttrain-mae:0.00689\tvalid-mae:0.20505\n",
      "[500]\ttrain-mae:0.00311\tvalid-mae:0.20507\n",
      "[600]\ttrain-mae:0.00142\tvalid-mae:0.20509\n",
      "[700]\ttrain-mae:0.00071\tvalid-mae:0.20507\n",
      "[800]\ttrain-mae:0.00053\tvalid-mae:0.20508\n",
      "[900]\ttrain-mae:0.00051\tvalid-mae:0.20508\n",
      "[1000]\ttrain-mae:0.00050\tvalid-mae:0.20508\n",
      "[1100]\ttrain-mae:0.00049\tvalid-mae:0.20508\n",
      "[1142]\ttrain-mae:0.00049\tvalid-mae:0.20508\n",
      "  ğŸ” Fold 3 MAE: 0.2051\n",
      "\n",
      "ğŸ” Fold 4/10\n",
      "[0]\ttrain-mae:0.20362\tvalid-mae:0.20151\n",
      "[100]\ttrain-mae:0.08728\tvalid-mae:0.19621\n",
      "[200]\ttrain-mae:0.03756\tvalid-mae:0.19583\n",
      "[300]\ttrain-mae:0.01614\tvalid-mae:0.19568\n",
      "[400]\ttrain-mae:0.00701\tvalid-mae:0.19575\n",
      "[500]\ttrain-mae:0.00308\tvalid-mae:0.19576\n",
      "[600]\ttrain-mae:0.00139\tvalid-mae:0.19578\n",
      "[700]\ttrain-mae:0.00067\tvalid-mae:0.19579\n",
      "[800]\ttrain-mae:0.00053\tvalid-mae:0.19579\n",
      "[900]\ttrain-mae:0.00051\tvalid-mae:0.19579\n",
      "[1000]\ttrain-mae:0.00050\tvalid-mae:0.19579\n",
      "[1100]\ttrain-mae:0.00050\tvalid-mae:0.19579\n",
      "[1200]\ttrain-mae:0.00049\tvalid-mae:0.19579\n",
      "[1275]\ttrain-mae:0.00049\tvalid-mae:0.19579\n",
      "  ğŸ” Fold 4 MAE: 0.1958\n",
      "\n",
      "ğŸ” Fold 5/10\n",
      "[0]\ttrain-mae:0.20284\tvalid-mae:0.20735\n",
      "[100]\ttrain-mae:0.08693\tvalid-mae:0.20235\n",
      "[200]\ttrain-mae:0.03747\tvalid-mae:0.20304\n",
      "[300]\ttrain-mae:0.01636\tvalid-mae:0.20358\n",
      "[400]\ttrain-mae:0.00707\tvalid-mae:0.20385\n",
      "[500]\ttrain-mae:0.00314\tvalid-mae:0.20395\n",
      "[600]\ttrain-mae:0.00142\tvalid-mae:0.20398\n",
      "[700]\ttrain-mae:0.00070\tvalid-mae:0.20399\n",
      "[800]\ttrain-mae:0.00053\tvalid-mae:0.20400\n",
      "[900]\ttrain-mae:0.00051\tvalid-mae:0.20400\n",
      "[1000]\ttrain-mae:0.00051\tvalid-mae:0.20400\n",
      "[1098]\ttrain-mae:0.00050\tvalid-mae:0.20400\n",
      "  ğŸ” Fold 5 MAE: 0.2040\n",
      "\n",
      "ğŸ” Fold 6/10\n",
      "[0]\ttrain-mae:0.20402\tvalid-mae:0.19918\n",
      "[100]\ttrain-mae:0.08836\tvalid-mae:0.19230\n",
      "[200]\ttrain-mae:0.03763\tvalid-mae:0.19224\n",
      "[300]\ttrain-mae:0.01656\tvalid-mae:0.19238\n",
      "[400]\ttrain-mae:0.00736\tvalid-mae:0.19248\n",
      "[500]\ttrain-mae:0.00336\tvalid-mae:0.19255\n",
      "[600]\ttrain-mae:0.00152\tvalid-mae:0.19258\n",
      "[700]\ttrain-mae:0.00075\tvalid-mae:0.19260\n",
      "[800]\ttrain-mae:0.00055\tvalid-mae:0.19260\n",
      "[900]\ttrain-mae:0.00053\tvalid-mae:0.19260\n",
      "[1000]\ttrain-mae:0.00051\tvalid-mae:0.19260\n",
      "[1100]\ttrain-mae:0.00050\tvalid-mae:0.19260\n",
      "[1130]\ttrain-mae:0.00049\tvalid-mae:0.19260\n",
      "  ğŸ” Fold 6 MAE: 0.1926\n",
      "\n",
      "ğŸ” Fold 7/10\n",
      "[0]\ttrain-mae:0.20372\tvalid-mae:0.20026\n",
      "[100]\ttrain-mae:0.08640\tvalid-mae:0.19518\n",
      "[200]\ttrain-mae:0.03646\tvalid-mae:0.19531\n",
      "[300]\ttrain-mae:0.01553\tvalid-mae:0.19557\n",
      "[400]\ttrain-mae:0.00670\tvalid-mae:0.19575\n",
      "[500]\ttrain-mae:0.00296\tvalid-mae:0.19576\n",
      "[600]\ttrain-mae:0.00134\tvalid-mae:0.19578\n",
      "[700]\ttrain-mae:0.00066\tvalid-mae:0.19578\n",
      "[800]\ttrain-mae:0.00052\tvalid-mae:0.19579\n",
      "[900]\ttrain-mae:0.00050\tvalid-mae:0.19579\n",
      "[1000]\ttrain-mae:0.00050\tvalid-mae:0.19579\n",
      "[1081]\ttrain-mae:0.00049\tvalid-mae:0.19579\n",
      "  ğŸ” Fold 7 MAE: 0.1958\n",
      "\n",
      "ğŸ” Fold 8/10\n",
      "[0]\ttrain-mae:0.20296\tvalid-mae:0.20683\n",
      "[100]\ttrain-mae:0.08749\tvalid-mae:0.19544\n",
      "[200]\ttrain-mae:0.03790\tvalid-mae:0.19252\n",
      "[300]\ttrain-mae:0.01657\tvalid-mae:0.19193\n",
      "[400]\ttrain-mae:0.00724\tvalid-mae:0.19159\n",
      "[500]\ttrain-mae:0.00329\tvalid-mae:0.19146\n",
      "[600]\ttrain-mae:0.00149\tvalid-mae:0.19138\n",
      "[700]\ttrain-mae:0.00074\tvalid-mae:0.19137\n",
      "[800]\ttrain-mae:0.00055\tvalid-mae:0.19137\n",
      "[900]\ttrain-mae:0.00053\tvalid-mae:0.19136\n",
      "[1000]\ttrain-mae:0.00052\tvalid-mae:0.19136\n",
      "[1100]\ttrain-mae:0.00051\tvalid-mae:0.19136\n",
      "[1200]\ttrain-mae:0.00050\tvalid-mae:0.19136\n",
      "[1300]\ttrain-mae:0.00050\tvalid-mae:0.19136\n",
      "[1400]\ttrain-mae:0.00050\tvalid-mae:0.19136\n",
      "[1500]\ttrain-mae:0.00050\tvalid-mae:0.19136\n",
      "[1600]\ttrain-mae:0.00049\tvalid-mae:0.19136\n",
      "[1700]\ttrain-mae:0.00049\tvalid-mae:0.19136\n",
      "[1800]\ttrain-mae:0.00049\tvalid-mae:0.19136\n",
      "[1900]\ttrain-mae:0.00049\tvalid-mae:0.19136\n",
      "[1999]\ttrain-mae:0.00049\tvalid-mae:0.19136\n",
      "  ğŸ” Fold 8 MAE: 0.1914\n",
      "\n",
      "ğŸ” Fold 9/10\n",
      "[0]\ttrain-mae:0.20346\tvalid-mae:0.20202\n",
      "[100]\ttrain-mae:0.08668\tvalid-mae:0.19209\n",
      "[200]\ttrain-mae:0.03739\tvalid-mae:0.18979\n",
      "[300]\ttrain-mae:0.01643\tvalid-mae:0.18915\n",
      "[400]\ttrain-mae:0.00727\tvalid-mae:0.18898\n",
      "[500]\ttrain-mae:0.00328\tvalid-mae:0.18889\n",
      "[600]\ttrain-mae:0.00152\tvalid-mae:0.18886\n",
      "[700]\ttrain-mae:0.00075\tvalid-mae:0.18884\n",
      "[800]\ttrain-mae:0.00054\tvalid-mae:0.18884\n",
      "[900]\ttrain-mae:0.00052\tvalid-mae:0.18884\n",
      "[1000]\ttrain-mae:0.00051\tvalid-mae:0.18884\n",
      "[1100]\ttrain-mae:0.00051\tvalid-mae:0.18884\n",
      "[1200]\ttrain-mae:0.00050\tvalid-mae:0.18884\n",
      "[1300]\ttrain-mae:0.00049\tvalid-mae:0.18884\n",
      "[1400]\ttrain-mae:0.00049\tvalid-mae:0.18884\n",
      "[1500]\ttrain-mae:0.00049\tvalid-mae:0.18884\n",
      "[1600]\ttrain-mae:0.00049\tvalid-mae:0.18884\n",
      "[1700]\ttrain-mae:0.00049\tvalid-mae:0.18884\n",
      "[1734]\ttrain-mae:0.00049\tvalid-mae:0.18884\n",
      "  ğŸ” Fold 9 MAE: 0.1888\n",
      "\n",
      "ğŸ” Fold 10/10\n",
      "[0]\ttrain-mae:0.20253\tvalid-mae:0.21128\n",
      "[100]\ttrain-mae:0.08515\tvalid-mae:0.20577\n",
      "[200]\ttrain-mae:0.03614\tvalid-mae:0.20523\n",
      "[300]\ttrain-mae:0.01538\tvalid-mae:0.20488\n",
      "[400]\ttrain-mae:0.00667\tvalid-mae:0.20467\n",
      "[500]\ttrain-mae:0.00295\tvalid-mae:0.20457\n",
      "[600]\ttrain-mae:0.00134\tvalid-mae:0.20453\n",
      "[700]\ttrain-mae:0.00066\tvalid-mae:0.20451\n",
      "[800]\ttrain-mae:0.00052\tvalid-mae:0.20451\n",
      "[900]\ttrain-mae:0.00050\tvalid-mae:0.20451\n",
      "[1000]\ttrain-mae:0.00049\tvalid-mae:0.20451\n",
      "[1100]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1200]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1300]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1400]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1500]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1600]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1700]\ttrain-mae:0.00048\tvalid-mae:0.20451\n",
      "[1800]\ttrain-mae:0.00047\tvalid-mae:0.20451\n",
      "[1846]\ttrain-mae:0.00047\tvalid-mae:0.20451\n",
      "  ğŸ” Fold 10 MAE: 0.2045\n",
      "\n",
      "âœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "ğŸ“‰ í‰ê·  MAE: 0.1964\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = train[features]\n",
    "y = train['ì„±ê³µí™•ë¥ ']\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "models = []\n",
    "cv_scores = []\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 27,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,\n",
    "    'tree_method': 'hist',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nğŸ” Fold {fold+1}/10\")\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "        early_stopping_rounds=1000,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dvalid)\n",
    "    score = mean_absolute_error(y_valid, preds)\n",
    "    print(f\"  ğŸ” Fold {fold+1} MAE: {score:.4f}\")\n",
    "\n",
    "    models.append(model)\n",
    "    cv_scores.append(score)\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“‰ í‰ê·  MAE: {sum(cv_scores)/len(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª Seed 13 ì‹œì‘\n",
      "\n",
      "ğŸ” Seed 13 - Fold 1/20\n",
      "[0]\ttrain-mae:0.20386\tvalid-mae:0.20343\n",
      "[100]\ttrain-mae:0.10247\tvalid-mae:0.19651\n",
      "[200]\ttrain-mae:0.05309\tvalid-mae:0.19672\n",
      "[300]\ttrain-mae:0.02756\tvalid-mae:0.19703\n",
      "[400]\ttrain-mae:0.01499\tvalid-mae:0.19750\n",
      "[500]\ttrain-mae:0.00842\tvalid-mae:0.19770\n",
      "[600]\ttrain-mae:0.00486\tvalid-mae:0.19773\n",
      "[700]\ttrain-mae:0.00279\tvalid-mae:0.19774\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.19777\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.19777\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19778\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19778\n",
      "[1125]\ttrain-mae:0.00059\tvalid-mae:0.19778\n",
      "  ğŸ” Fold MAE: 0.1978\n",
      "\n",
      "ğŸ” Seed 13 - Fold 2/20\n",
      "[0]\ttrain-mae:0.20347\tvalid-mae:0.20905\n",
      "[100]\ttrain-mae:0.10424\tvalid-mae:0.19978\n",
      "[200]\ttrain-mae:0.05496\tvalid-mae:0.19779\n",
      "[300]\ttrain-mae:0.02918\tvalid-mae:0.19694\n",
      "[400]\ttrain-mae:0.01580\tvalid-mae:0.19635\n",
      "[500]\ttrain-mae:0.00899\tvalid-mae:0.19618\n",
      "[600]\ttrain-mae:0.00510\tvalid-mae:0.19589\n",
      "[700]\ttrain-mae:0.00296\tvalid-mae:0.19588\n",
      "[800]\ttrain-mae:0.00177\tvalid-mae:0.19582\n",
      "[900]\ttrain-mae:0.00107\tvalid-mae:0.19579\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.19578\n",
      "[1100]\ttrain-mae:0.00062\tvalid-mae:0.19578\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19578\n",
      "[1300]\ttrain-mae:0.00058\tvalid-mae:0.19578\n",
      "[1400]\ttrain-mae:0.00057\tvalid-mae:0.19578\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.19578\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19578\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19578\n",
      "[1800]\ttrain-mae:0.00055\tvalid-mae:0.19578\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19578\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19578\n",
      "  ğŸ” Fold MAE: 0.1958\n",
      "\n",
      "ğŸ” Seed 13 - Fold 3/20\n",
      "[0]\ttrain-mae:0.20345\tvalid-mae:0.20395\n",
      "[100]\ttrain-mae:0.10649\tvalid-mae:0.19331\n",
      "[200]\ttrain-mae:0.05647\tvalid-mae:0.19096\n",
      "[300]\ttrain-mae:0.03079\tvalid-mae:0.19011\n",
      "[400]\ttrain-mae:0.01706\tvalid-mae:0.18952\n",
      "[500]\ttrain-mae:0.00966\tvalid-mae:0.18933\n",
      "[600]\ttrain-mae:0.00562\tvalid-mae:0.18923\n",
      "[700]\ttrain-mae:0.00332\tvalid-mae:0.18921\n",
      "[800]\ttrain-mae:0.00195\tvalid-mae:0.18919\n",
      "[900]\ttrain-mae:0.00118\tvalid-mae:0.18918\n",
      "[1000]\ttrain-mae:0.00075\tvalid-mae:0.18916\n",
      "[1100]\ttrain-mae:0.00062\tvalid-mae:0.18916\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.18916\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18916\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18916\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.18916\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.18916\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.18916\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.18916\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.18916\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.18916\n",
      "  ğŸ” Fold MAE: 0.1892\n",
      "\n",
      "ğŸ” Seed 13 - Fold 4/20\n",
      "[0]\ttrain-mae:0.20353\tvalid-mae:0.19996\n",
      "[100]\ttrain-mae:0.10658\tvalid-mae:0.18817\n",
      "[200]\ttrain-mae:0.05529\tvalid-mae:0.18641\n",
      "[300]\ttrain-mae:0.02914\tvalid-mae:0.18565\n",
      "[400]\ttrain-mae:0.01556\tvalid-mae:0.18524\n",
      "[500]\ttrain-mae:0.00862\tvalid-mae:0.18503\n",
      "[600]\ttrain-mae:0.00479\tvalid-mae:0.18503\n",
      "[700]\ttrain-mae:0.00268\tvalid-mae:0.18504\n",
      "[800]\ttrain-mae:0.00150\tvalid-mae:0.18502\n",
      "[900]\ttrain-mae:0.00090\tvalid-mae:0.18502\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.18502\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.18501\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18501\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.18501\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18501\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.18501\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.18501\n",
      "[1645]\ttrain-mae:0.00055\tvalid-mae:0.18501\n",
      "  ğŸ” Fold MAE: 0.1850\n",
      "\n",
      "ğŸ” Seed 13 - Fold 5/20\n",
      "[0]\ttrain-mae:0.20326\tvalid-mae:0.20570\n",
      "[100]\ttrain-mae:0.10176\tvalid-mae:0.20124\n",
      "[200]\ttrain-mae:0.05205\tvalid-mae:0.20094\n",
      "[300]\ttrain-mae:0.02773\tvalid-mae:0.20071\n",
      "[400]\ttrain-mae:0.01502\tvalid-mae:0.20043\n",
      "[500]\ttrain-mae:0.00825\tvalid-mae:0.20044\n",
      "[600]\ttrain-mae:0.00468\tvalid-mae:0.20044\n",
      "[700]\ttrain-mae:0.00268\tvalid-mae:0.20044\n",
      "[800]\ttrain-mae:0.00156\tvalid-mae:0.20041\n",
      "[900]\ttrain-mae:0.00093\tvalid-mae:0.20041\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.20041\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20041\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20041\n",
      "[1300]\ttrain-mae:0.00055\tvalid-mae:0.20041\n",
      "[1366]\ttrain-mae:0.00055\tvalid-mae:0.20041\n",
      "  ğŸ” Fold MAE: 0.2004\n",
      "\n",
      "ğŸ” Seed 13 - Fold 6/20\n",
      "[0]\ttrain-mae:0.20325\tvalid-mae:0.20879\n",
      "[100]\ttrain-mae:0.10561\tvalid-mae:0.20456\n",
      "[200]\ttrain-mae:0.05584\tvalid-mae:0.20443\n",
      "[300]\ttrain-mae:0.02976\tvalid-mae:0.20469\n",
      "[400]\ttrain-mae:0.01675\tvalid-mae:0.20512\n",
      "[500]\ttrain-mae:0.00930\tvalid-mae:0.20534\n",
      "[600]\ttrain-mae:0.00531\tvalid-mae:0.20545\n",
      "[700]\ttrain-mae:0.00303\tvalid-mae:0.20545\n",
      "[800]\ttrain-mae:0.00179\tvalid-mae:0.20549\n",
      "[900]\ttrain-mae:0.00109\tvalid-mae:0.20550\n",
      "[1000]\ttrain-mae:0.00071\tvalid-mae:0.20551\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.20551\n",
      "[1140]\ttrain-mae:0.00059\tvalid-mae:0.20551\n",
      "  ğŸ” Fold MAE: 0.2055\n",
      "\n",
      "ğŸ” Seed 13 - Fold 7/20\n",
      "[0]\ttrain-mae:0.20325\tvalid-mae:0.21133\n",
      "[100]\ttrain-mae:0.10571\tvalid-mae:0.20060\n",
      "[200]\ttrain-mae:0.05460\tvalid-mae:0.19728\n",
      "[300]\ttrain-mae:0.02812\tvalid-mae:0.19627\n",
      "[400]\ttrain-mae:0.01531\tvalid-mae:0.19579\n",
      "[500]\ttrain-mae:0.00852\tvalid-mae:0.19563\n",
      "[600]\ttrain-mae:0.00476\tvalid-mae:0.19560\n",
      "[700]\ttrain-mae:0.00276\tvalid-mae:0.19559\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.19554\n",
      "[900]\ttrain-mae:0.00099\tvalid-mae:0.19551\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19550\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.19550\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19551\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19551\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19551\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19550\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19550\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19550\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.19551\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.19551\n",
      "[1997]\ttrain-mae:0.00053\tvalid-mae:0.19551\n",
      "  ğŸ” Fold MAE: 0.1955\n",
      "\n",
      "ğŸ” Seed 13 - Fold 8/20\n",
      "[0]\ttrain-mae:0.20351\tvalid-mae:0.20514\n",
      "[100]\ttrain-mae:0.10448\tvalid-mae:0.19662\n",
      "[200]\ttrain-mae:0.05494\tvalid-mae:0.19557\n",
      "[300]\ttrain-mae:0.02835\tvalid-mae:0.19503\n",
      "[400]\ttrain-mae:0.01541\tvalid-mae:0.19512\n",
      "[500]\ttrain-mae:0.00851\tvalid-mae:0.19520\n",
      "[600]\ttrain-mae:0.00474\tvalid-mae:0.19516\n",
      "[700]\ttrain-mae:0.00271\tvalid-mae:0.19515\n",
      "[800]\ttrain-mae:0.00160\tvalid-mae:0.19513\n",
      "[900]\ttrain-mae:0.00095\tvalid-mae:0.19513\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19513\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19512\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19512\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19512\n",
      "[1340]\ttrain-mae:0.00056\tvalid-mae:0.19512\n",
      "  ğŸ” Fold MAE: 0.1951\n",
      "\n",
      "ğŸ” Seed 13 - Fold 9/20\n",
      "[0]\ttrain-mae:0.20387\tvalid-mae:0.20081\n",
      "[100]\ttrain-mae:0.10555\tvalid-mae:0.19273\n",
      "[200]\ttrain-mae:0.05513\tvalid-mae:0.19041\n",
      "[300]\ttrain-mae:0.02991\tvalid-mae:0.19006\n",
      "[400]\ttrain-mae:0.01658\tvalid-mae:0.18955\n",
      "[500]\ttrain-mae:0.00939\tvalid-mae:0.18942\n",
      "[600]\ttrain-mae:0.00544\tvalid-mae:0.18951\n",
      "[700]\ttrain-mae:0.00309\tvalid-mae:0.18962\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.18964\n",
      "[900]\ttrain-mae:0.00106\tvalid-mae:0.18963\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.18963\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.18963\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18963\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.18963\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.18963\n",
      "[1499]\ttrain-mae:0.00054\tvalid-mae:0.18963\n",
      "  ğŸ” Fold MAE: 0.1896\n",
      "\n",
      "ğŸ” Seed 13 - Fold 10/20\n",
      "[0]\ttrain-mae:0.20445\tvalid-mae:0.18735\n",
      "[100]\ttrain-mae:0.10107\tvalid-mae:0.18203\n",
      "[200]\ttrain-mae:0.05263\tvalid-mae:0.18248\n",
      "[300]\ttrain-mae:0.02745\tvalid-mae:0.18342\n",
      "[400]\ttrain-mae:0.01473\tvalid-mae:0.18393\n",
      "[500]\ttrain-mae:0.00817\tvalid-mae:0.18417\n",
      "[600]\ttrain-mae:0.00464\tvalid-mae:0.18423\n",
      "[700]\ttrain-mae:0.00268\tvalid-mae:0.18426\n",
      "[800]\ttrain-mae:0.00158\tvalid-mae:0.18427\n",
      "[900]\ttrain-mae:0.00095\tvalid-mae:0.18429\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.18431\n",
      "[1076]\ttrain-mae:0.00059\tvalid-mae:0.18431\n",
      "  ğŸ” Fold MAE: 0.1843\n",
      "\n",
      "ğŸ” Seed 13 - Fold 11/20\n",
      "[0]\ttrain-mae:0.20364\tvalid-mae:0.20230\n",
      "[100]\ttrain-mae:0.10398\tvalid-mae:0.19872\n",
      "[200]\ttrain-mae:0.05515\tvalid-mae:0.19797\n",
      "[300]\ttrain-mae:0.02862\tvalid-mae:0.19772\n",
      "[400]\ttrain-mae:0.01535\tvalid-mae:0.19751\n",
      "[500]\ttrain-mae:0.00843\tvalid-mae:0.19743\n",
      "[600]\ttrain-mae:0.00481\tvalid-mae:0.19737\n",
      "[700]\ttrain-mae:0.00290\tvalid-mae:0.19731\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.19729\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.19727\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.19728\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19728\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19728\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19728\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.19728\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19728\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19728\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19728\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19728\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19728\n",
      "[1941]\ttrain-mae:0.00053\tvalid-mae:0.19728\n",
      "  ğŸ” Fold MAE: 0.1973\n",
      "\n",
      "ğŸ” Seed 13 - Fold 12/20\n",
      "[0]\ttrain-mae:0.20313\tvalid-mae:0.21203\n",
      "[100]\ttrain-mae:0.10823\tvalid-mae:0.20556\n",
      "[200]\ttrain-mae:0.05632\tvalid-mae:0.20487\n",
      "[300]\ttrain-mae:0.02898\tvalid-mae:0.20422\n",
      "[400]\ttrain-mae:0.01590\tvalid-mae:0.20419\n",
      "[500]\ttrain-mae:0.00908\tvalid-mae:0.20429\n",
      "[600]\ttrain-mae:0.00511\tvalid-mae:0.20436\n",
      "[700]\ttrain-mae:0.00286\tvalid-mae:0.20437\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.20438\n",
      "[900]\ttrain-mae:0.00097\tvalid-mae:0.20440\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.20439\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.20439\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20439\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.20439\n",
      "[1364]\ttrain-mae:0.00056\tvalid-mae:0.20439\n",
      "  ğŸ” Fold MAE: 0.2044\n",
      "\n",
      "ğŸ” Seed 13 - Fold 13/20\n",
      "[0]\ttrain-mae:0.20356\tvalid-mae:0.20656\n",
      "[100]\ttrain-mae:0.10499\tvalid-mae:0.19856\n",
      "[200]\ttrain-mae:0.05488\tvalid-mae:0.19638\n",
      "[300]\ttrain-mae:0.03041\tvalid-mae:0.19583\n",
      "[400]\ttrain-mae:0.01662\tvalid-mae:0.19563\n",
      "[500]\ttrain-mae:0.00906\tvalid-mae:0.19553\n",
      "[600]\ttrain-mae:0.00510\tvalid-mae:0.19544\n",
      "[700]\ttrain-mae:0.00295\tvalid-mae:0.19538\n",
      "[800]\ttrain-mae:0.00175\tvalid-mae:0.19537\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19537\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.19536\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19536\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19536\n",
      "[1300]\ttrain-mae:0.00058\tvalid-mae:0.19536\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19536\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19536\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19536\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19536\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19536\n",
      "[1853]\ttrain-mae:0.00054\tvalid-mae:0.19536\n",
      "  ğŸ” Fold MAE: 0.1954\n",
      "\n",
      "ğŸ” Seed 13 - Fold 14/20\n",
      "[0]\ttrain-mae:0.20377\tvalid-mae:0.20013\n",
      "[100]\ttrain-mae:0.10375\tvalid-mae:0.19180\n",
      "[200]\ttrain-mae:0.05397\tvalid-mae:0.18892\n",
      "[300]\ttrain-mae:0.02894\tvalid-mae:0.18733\n",
      "[400]\ttrain-mae:0.01550\tvalid-mae:0.18713\n",
      "[500]\ttrain-mae:0.00853\tvalid-mae:0.18708\n",
      "[600]\ttrain-mae:0.00485\tvalid-mae:0.18702\n",
      "[700]\ttrain-mae:0.00275\tvalid-mae:0.18699\n",
      "[800]\ttrain-mae:0.00156\tvalid-mae:0.18699\n",
      "[900]\ttrain-mae:0.00094\tvalid-mae:0.18698\n",
      "[1000]\ttrain-mae:0.00064\tvalid-mae:0.18698\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.18698\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.18698\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.18698\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.18698\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.18698\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.18698\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.18698\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18698\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.18698\n",
      "[1938]\ttrain-mae:0.00053\tvalid-mae:0.18698\n",
      "  ğŸ” Fold MAE: 0.1870\n",
      "\n",
      "ğŸ” Seed 13 - Fold 15/20\n",
      "[0]\ttrain-mae:0.20293\tvalid-mae:0.21423\n",
      "[100]\ttrain-mae:0.10560\tvalid-mae:0.20618\n",
      "[200]\ttrain-mae:0.05523\tvalid-mae:0.20455\n",
      "[300]\ttrain-mae:0.02967\tvalid-mae:0.20394\n",
      "[400]\ttrain-mae:0.01641\tvalid-mae:0.20372\n",
      "[500]\ttrain-mae:0.00914\tvalid-mae:0.20367\n",
      "[600]\ttrain-mae:0.00519\tvalid-mae:0.20368\n",
      "[700]\ttrain-mae:0.00293\tvalid-mae:0.20363\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.20366\n",
      "[900]\ttrain-mae:0.00103\tvalid-mae:0.20366\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.20367\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.20367\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20367\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.20367\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20367\n",
      "[1476]\ttrain-mae:0.00056\tvalid-mae:0.20367\n",
      "  ğŸ” Fold MAE: 0.2037\n",
      "\n",
      "ğŸ” Seed 13 - Fold 16/20\n",
      "[0]\ttrain-mae:0.20346\tvalid-mae:0.20767\n",
      "[100]\ttrain-mae:0.10377\tvalid-mae:0.20405\n",
      "[200]\ttrain-mae:0.05523\tvalid-mae:0.20420\n",
      "[300]\ttrain-mae:0.02975\tvalid-mae:0.20331\n",
      "[400]\ttrain-mae:0.01611\tvalid-mae:0.20306\n",
      "[500]\ttrain-mae:0.00905\tvalid-mae:0.20292\n",
      "[600]\ttrain-mae:0.00522\tvalid-mae:0.20278\n",
      "[700]\ttrain-mae:0.00296\tvalid-mae:0.20270\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.20266\n",
      "[900]\ttrain-mae:0.00106\tvalid-mae:0.20264\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.20263\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20263\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20263\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.20263\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.20262\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20263\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.20263\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.20262\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.20262\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.20262\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.20262\n",
      "  ğŸ” Fold MAE: 0.2026\n",
      "\n",
      "ğŸ” Seed 13 - Fold 17/20\n",
      "[0]\ttrain-mae:0.20337\tvalid-mae:0.20834\n",
      "[100]\ttrain-mae:0.10355\tvalid-mae:0.20273\n",
      "[200]\ttrain-mae:0.05304\tvalid-mae:0.20159\n",
      "[300]\ttrain-mae:0.02773\tvalid-mae:0.20113\n",
      "[400]\ttrain-mae:0.01518\tvalid-mae:0.20079\n",
      "[500]\ttrain-mae:0.00864\tvalid-mae:0.20076\n",
      "[600]\ttrain-mae:0.00485\tvalid-mae:0.20082\n",
      "[700]\ttrain-mae:0.00278\tvalid-mae:0.20078\n",
      "[800]\ttrain-mae:0.00163\tvalid-mae:0.20075\n",
      "[900]\ttrain-mae:0.00098\tvalid-mae:0.20075\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.20075\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.20075\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20075\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.20075\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20075\n",
      "[1492]\ttrain-mae:0.00055\tvalid-mae:0.20075\n",
      "  ğŸ” Fold MAE: 0.2008\n",
      "\n",
      "ğŸ” Seed 13 - Fold 18/20\n",
      "[0]\ttrain-mae:0.20293\tvalid-mae:0.21232\n",
      "[100]\ttrain-mae:0.10465\tvalid-mae:0.19935\n",
      "[200]\ttrain-mae:0.05558\tvalid-mae:0.19390\n",
      "[300]\ttrain-mae:0.02930\tvalid-mae:0.19201\n",
      "[400]\ttrain-mae:0.01625\tvalid-mae:0.19113\n",
      "[500]\ttrain-mae:0.00893\tvalid-mae:0.19084\n",
      "[600]\ttrain-mae:0.00521\tvalid-mae:0.19052\n",
      "[700]\ttrain-mae:0.00295\tvalid-mae:0.19039\n",
      "[800]\ttrain-mae:0.00172\tvalid-mae:0.19033\n",
      "[900]\ttrain-mae:0.00103\tvalid-mae:0.19030\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.19027\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19027\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19027\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19027\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19026\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19026\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19026\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19026\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19026\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.19026\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.19026\n",
      "  ğŸ” Fold MAE: 0.1903\n",
      "\n",
      "ğŸ” Seed 13 - Fold 19/20\n",
      "[0]\ttrain-mae:0.20351\tvalid-mae:0.20654\n",
      "[100]\ttrain-mae:0.10355\tvalid-mae:0.19920\n",
      "[200]\ttrain-mae:0.05469\tvalid-mae:0.19765\n",
      "[300]\ttrain-mae:0.03009\tvalid-mae:0.19749\n",
      "[400]\ttrain-mae:0.01678\tvalid-mae:0.19741\n",
      "[500]\ttrain-mae:0.00926\tvalid-mae:0.19739\n",
      "[600]\ttrain-mae:0.00516\tvalid-mae:0.19731\n",
      "[700]\ttrain-mae:0.00299\tvalid-mae:0.19727\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.19724\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19724\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19723\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19724\n",
      "[1200]\ttrain-mae:0.00060\tvalid-mae:0.19724\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19724\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19724\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19724\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19724\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19724\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19724\n",
      "[1838]\ttrain-mae:0.00054\tvalid-mae:0.19724\n",
      "  ğŸ” Fold MAE: 0.1972\n",
      "\n",
      "ğŸ” Seed 13 - Fold 20/20\n",
      "[0]\ttrain-mae:0.20442\tvalid-mae:0.19154\n",
      "[100]\ttrain-mae:0.10237\tvalid-mae:0.18828\n",
      "[200]\ttrain-mae:0.05190\tvalid-mae:0.18950\n",
      "[300]\ttrain-mae:0.02739\tvalid-mae:0.19031\n",
      "[400]\ttrain-mae:0.01523\tvalid-mae:0.19070\n",
      "[500]\ttrain-mae:0.00857\tvalid-mae:0.19083\n",
      "[600]\ttrain-mae:0.00484\tvalid-mae:0.19095\n",
      "[700]\ttrain-mae:0.00277\tvalid-mae:0.19103\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.19108\n",
      "[900]\ttrain-mae:0.00100\tvalid-mae:0.19109\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19110\n",
      "[1084]\ttrain-mae:0.00061\tvalid-mae:0.19110\n",
      "  ğŸ” Fold MAE: 0.1911\n",
      "\n",
      "ğŸ§ª Seed 42 ì‹œì‘\n",
      "\n",
      "ğŸ” Seed 42 - Fold 1/20\n",
      "[0]\ttrain-mae:0.20311\tvalid-mae:0.21044\n",
      "[100]\ttrain-mae:0.10464\tvalid-mae:0.19849\n",
      "[200]\ttrain-mae:0.05433\tvalid-mae:0.19537\n",
      "[300]\ttrain-mae:0.02846\tvalid-mae:0.19372\n",
      "[400]\ttrain-mae:0.01562\tvalid-mae:0.19320\n",
      "[500]\ttrain-mae:0.00874\tvalid-mae:0.19290\n",
      "[600]\ttrain-mae:0.00514\tvalid-mae:0.19277\n",
      "[700]\ttrain-mae:0.00299\tvalid-mae:0.19262\n",
      "[800]\ttrain-mae:0.00173\tvalid-mae:0.19255\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.19252\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19251\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19251\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19251\n",
      "[1300]\ttrain-mae:0.00058\tvalid-mae:0.19251\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19251\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.19251\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19251\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19251\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19251\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19251\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19251\n",
      "  ğŸ” Fold MAE: 0.1925\n",
      "\n",
      "ğŸ” Seed 42 - Fold 2/20\n",
      "[0]\ttrain-mae:0.20419\tvalid-mae:0.19025\n",
      "[100]\ttrain-mae:0.10000\tvalid-mae:0.18488\n",
      "[200]\ttrain-mae:0.05078\tvalid-mae:0.18573\n",
      "[300]\ttrain-mae:0.02674\tvalid-mae:0.18605\n",
      "[400]\ttrain-mae:0.01440\tvalid-mae:0.18644\n",
      "[500]\ttrain-mae:0.00799\tvalid-mae:0.18667\n",
      "[600]\ttrain-mae:0.00460\tvalid-mae:0.18669\n",
      "[700]\ttrain-mae:0.00267\tvalid-mae:0.18675\n",
      "[800]\ttrain-mae:0.00156\tvalid-mae:0.18678\n",
      "[900]\ttrain-mae:0.00090\tvalid-mae:0.18679\n",
      "[1000]\ttrain-mae:0.00064\tvalid-mae:0.18680\n",
      "[1076]\ttrain-mae:0.00059\tvalid-mae:0.18680\n",
      "  ğŸ” Fold MAE: 0.1868\n",
      "\n",
      "ğŸ” Seed 42 - Fold 3/20\n",
      "[0]\ttrain-mae:0.20381\tvalid-mae:0.20271\n",
      "[100]\ttrain-mae:0.10445\tvalid-mae:0.19045\n",
      "[200]\ttrain-mae:0.05408\tvalid-mae:0.18761\n",
      "[300]\ttrain-mae:0.02910\tvalid-mae:0.18646\n",
      "[400]\ttrain-mae:0.01558\tvalid-mae:0.18575\n",
      "[500]\ttrain-mae:0.00855\tvalid-mae:0.18546\n",
      "[600]\ttrain-mae:0.00479\tvalid-mae:0.18536\n",
      "[700]\ttrain-mae:0.00270\tvalid-mae:0.18534\n",
      "[800]\ttrain-mae:0.00159\tvalid-mae:0.18532\n",
      "[900]\ttrain-mae:0.00096\tvalid-mae:0.18531\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.18531\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.18532\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.18532\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.18532\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.18532\n",
      "[1500]\ttrain-mae:0.00054\tvalid-mae:0.18532\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.18532\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.18532\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18532\n",
      "[1865]\ttrain-mae:0.00053\tvalid-mae:0.18532\n",
      "  ğŸ” Fold MAE: 0.1853\n",
      "\n",
      "ğŸ” Seed 42 - Fold 4/20\n",
      "[0]\ttrain-mae:0.20280\tvalid-mae:0.21740\n",
      "[100]\ttrain-mae:0.10403\tvalid-mae:0.20531\n",
      "[200]\ttrain-mae:0.05463\tvalid-mae:0.20126\n",
      "[300]\ttrain-mae:0.02866\tvalid-mae:0.20019\n",
      "[400]\ttrain-mae:0.01554\tvalid-mae:0.19994\n",
      "[500]\ttrain-mae:0.00879\tvalid-mae:0.19984\n",
      "[600]\ttrain-mae:0.00500\tvalid-mae:0.19984\n",
      "[700]\ttrain-mae:0.00287\tvalid-mae:0.19982\n",
      "[800]\ttrain-mae:0.00169\tvalid-mae:0.19981\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.19982\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19981\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19982\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19981\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19981\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.19981\n",
      "[1500]\ttrain-mae:0.00054\tvalid-mae:0.19981\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19981\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19981\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19981\n",
      "[1838]\ttrain-mae:0.00053\tvalid-mae:0.19981\n",
      "  ğŸ” Fold MAE: 0.1998\n",
      "\n",
      "ğŸ” Seed 42 - Fold 5/20\n",
      "[0]\ttrain-mae:0.20418\tvalid-mae:0.19458\n",
      "[100]\ttrain-mae:0.10310\tvalid-mae:0.18933\n",
      "[200]\ttrain-mae:0.05274\tvalid-mae:0.18904\n",
      "[300]\ttrain-mae:0.02760\tvalid-mae:0.18925\n",
      "[400]\ttrain-mae:0.01545\tvalid-mae:0.18946\n",
      "[500]\ttrain-mae:0.00862\tvalid-mae:0.18937\n",
      "[600]\ttrain-mae:0.00483\tvalid-mae:0.18934\n",
      "[700]\ttrain-mae:0.00276\tvalid-mae:0.18934\n",
      "[800]\ttrain-mae:0.00161\tvalid-mae:0.18933\n",
      "[900]\ttrain-mae:0.00094\tvalid-mae:0.18934\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.18934\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.18934\n",
      "[1176]\ttrain-mae:0.00058\tvalid-mae:0.18934\n",
      "  ğŸ” Fold MAE: 0.1893\n",
      "\n",
      "ğŸ” Seed 42 - Fold 6/20\n",
      "[0]\ttrain-mae:0.20245\tvalid-mae:0.22676\n",
      "[100]\ttrain-mae:0.10491\tvalid-mae:0.22105\n",
      "[200]\ttrain-mae:0.05531\tvalid-mae:0.21970\n",
      "[300]\ttrain-mae:0.02942\tvalid-mae:0.21960\n",
      "[400]\ttrain-mae:0.01614\tvalid-mae:0.21957\n",
      "[500]\ttrain-mae:0.00894\tvalid-mae:0.21950\n",
      "[600]\ttrain-mae:0.00500\tvalid-mae:0.21941\n",
      "[700]\ttrain-mae:0.00284\tvalid-mae:0.21944\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.21942\n",
      "[900]\ttrain-mae:0.00097\tvalid-mae:0.21943\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.21943\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.21943\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.21943\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.21943\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.21943\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.21943\n",
      "[1553]\ttrain-mae:0.00055\tvalid-mae:0.21943\n",
      "  ğŸ” Fold MAE: 0.2194\n",
      "\n",
      "ğŸ” Seed 42 - Fold 7/20\n",
      "[0]\ttrain-mae:0.20399\tvalid-mae:0.20034\n",
      "[100]\ttrain-mae:0.10718\tvalid-mae:0.19710\n",
      "[200]\ttrain-mae:0.05685\tvalid-mae:0.19794\n",
      "[300]\ttrain-mae:0.03106\tvalid-mae:0.19826\n",
      "[400]\ttrain-mae:0.01673\tvalid-mae:0.19845\n",
      "[500]\ttrain-mae:0.00940\tvalid-mae:0.19856\n",
      "[600]\ttrain-mae:0.00557\tvalid-mae:0.19857\n",
      "[700]\ttrain-mae:0.00324\tvalid-mae:0.19851\n",
      "[800]\ttrain-mae:0.00185\tvalid-mae:0.19849\n",
      "[900]\ttrain-mae:0.00110\tvalid-mae:0.19850\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.19850\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19850\n",
      "[1106]\ttrain-mae:0.00060\tvalid-mae:0.19850\n",
      "  ğŸ” Fold MAE: 0.1985\n",
      "\n",
      "ğŸ” Seed 42 - Fold 8/20\n",
      "[0]\ttrain-mae:0.20420\tvalid-mae:0.20173\n",
      "[100]\ttrain-mae:0.10353\tvalid-mae:0.19595\n",
      "[200]\ttrain-mae:0.05349\tvalid-mae:0.19536\n",
      "[300]\ttrain-mae:0.02752\tvalid-mae:0.19549\n",
      "[400]\ttrain-mae:0.01501\tvalid-mae:0.19558\n",
      "[500]\ttrain-mae:0.00834\tvalid-mae:0.19561\n",
      "[600]\ttrain-mae:0.00477\tvalid-mae:0.19557\n",
      "[700]\ttrain-mae:0.00269\tvalid-mae:0.19560\n",
      "[800]\ttrain-mae:0.00155\tvalid-mae:0.19559\n",
      "[900]\ttrain-mae:0.00093\tvalid-mae:0.19560\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19561\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.19561\n",
      "[1181]\ttrain-mae:0.00057\tvalid-mae:0.19561\n",
      "  ğŸ” Fold MAE: 0.1956\n",
      "\n",
      "ğŸ” Seed 42 - Fold 9/20\n",
      "[0]\ttrain-mae:0.20354\tvalid-mae:0.20884\n",
      "[100]\ttrain-mae:0.10520\tvalid-mae:0.20027\n",
      "[200]\ttrain-mae:0.05432\tvalid-mae:0.19932\n",
      "[300]\ttrain-mae:0.02917\tvalid-mae:0.19969\n",
      "[400]\ttrain-mae:0.01664\tvalid-mae:0.19964\n",
      "[500]\ttrain-mae:0.00925\tvalid-mae:0.19989\n",
      "[600]\ttrain-mae:0.00512\tvalid-mae:0.19995\n",
      "[700]\ttrain-mae:0.00295\tvalid-mae:0.19995\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.19998\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19999\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.20000\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.20000\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.20000\n",
      "[1232]\ttrain-mae:0.00058\tvalid-mae:0.20001\n",
      "  ğŸ” Fold MAE: 0.2000\n",
      "\n",
      "ğŸ” Seed 42 - Fold 10/20\n",
      "[0]\ttrain-mae:0.20333\tvalid-mae:0.20631\n",
      "[100]\ttrain-mae:0.10700\tvalid-mae:0.19971\n",
      "[200]\ttrain-mae:0.05603\tvalid-mae:0.19902\n",
      "[300]\ttrain-mae:0.02917\tvalid-mae:0.19859\n",
      "[400]\ttrain-mae:0.01578\tvalid-mae:0.19884\n",
      "[500]\ttrain-mae:0.00868\tvalid-mae:0.19893\n",
      "[600]\ttrain-mae:0.00496\tvalid-mae:0.19906\n",
      "[700]\ttrain-mae:0.00286\tvalid-mae:0.19907\n",
      "[800]\ttrain-mae:0.00163\tvalid-mae:0.19906\n",
      "[900]\ttrain-mae:0.00098\tvalid-mae:0.19906\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.19906\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19907\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19907\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19907\n",
      "  ğŸ” Fold MAE: 0.1991\n",
      "\n",
      "ğŸ” Seed 42 - Fold 11/20\n",
      "[0]\ttrain-mae:0.20446\tvalid-mae:0.19624\n",
      "[100]\ttrain-mae:0.10399\tvalid-mae:0.19291\n",
      "[200]\ttrain-mae:0.05461\tvalid-mae:0.19495\n",
      "[300]\ttrain-mae:0.02926\tvalid-mae:0.19675\n",
      "[400]\ttrain-mae:0.01615\tvalid-mae:0.19750\n",
      "[500]\ttrain-mae:0.00885\tvalid-mae:0.19792\n",
      "[600]\ttrain-mae:0.00510\tvalid-mae:0.19810\n",
      "[700]\ttrain-mae:0.00289\tvalid-mae:0.19817\n",
      "[800]\ttrain-mae:0.00166\tvalid-mae:0.19819\n",
      "[900]\ttrain-mae:0.00096\tvalid-mae:0.19821\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19823\n",
      "[1083]\ttrain-mae:0.00060\tvalid-mae:0.19823\n",
      "  ğŸ” Fold MAE: 0.1982\n",
      "\n",
      "ğŸ” Seed 42 - Fold 12/20\n",
      "[0]\ttrain-mae:0.20379\tvalid-mae:0.20222\n",
      "[100]\ttrain-mae:0.10796\tvalid-mae:0.19252\n",
      "[200]\ttrain-mae:0.05829\tvalid-mae:0.19052\n",
      "[300]\ttrain-mae:0.03091\tvalid-mae:0.19008\n",
      "[400]\ttrain-mae:0.01693\tvalid-mae:0.18966\n",
      "[500]\ttrain-mae:0.00939\tvalid-mae:0.18966\n",
      "[600]\ttrain-mae:0.00536\tvalid-mae:0.18968\n",
      "[700]\ttrain-mae:0.00321\tvalid-mae:0.18968\n",
      "[800]\ttrain-mae:0.00188\tvalid-mae:0.18965\n",
      "[900]\ttrain-mae:0.00111\tvalid-mae:0.18963\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.18963\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18963\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18963\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18963\n",
      "[1379]\ttrain-mae:0.00055\tvalid-mae:0.18963\n",
      "  ğŸ” Fold MAE: 0.1896\n",
      "\n",
      "ğŸ” Seed 42 - Fold 13/20\n",
      "[0]\ttrain-mae:0.20417\tvalid-mae:0.19301\n",
      "[100]\ttrain-mae:0.10436\tvalid-mae:0.18870\n",
      "[200]\ttrain-mae:0.05295\tvalid-mae:0.18795\n",
      "[300]\ttrain-mae:0.02783\tvalid-mae:0.18846\n",
      "[400]\ttrain-mae:0.01507\tvalid-mae:0.18876\n",
      "[500]\ttrain-mae:0.00830\tvalid-mae:0.18899\n",
      "[600]\ttrain-mae:0.00472\tvalid-mae:0.18905\n",
      "[700]\ttrain-mae:0.00271\tvalid-mae:0.18912\n",
      "[800]\ttrain-mae:0.00158\tvalid-mae:0.18915\n",
      "[900]\ttrain-mae:0.00095\tvalid-mae:0.18916\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.18916\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.18917\n",
      "[1148]\ttrain-mae:0.00059\tvalid-mae:0.18917\n",
      "  ğŸ” Fold MAE: 0.1892\n",
      "\n",
      "ğŸ” Seed 42 - Fold 14/20\n",
      "[0]\ttrain-mae:0.20363\tvalid-mae:0.20731\n",
      "[100]\ttrain-mae:0.10463\tvalid-mae:0.20134\n",
      "[200]\ttrain-mae:0.05338\tvalid-mae:0.19914\n",
      "[300]\ttrain-mae:0.02843\tvalid-mae:0.19839\n",
      "[400]\ttrain-mae:0.01559\tvalid-mae:0.19805\n",
      "[500]\ttrain-mae:0.00895\tvalid-mae:0.19805\n",
      "[600]\ttrain-mae:0.00512\tvalid-mae:0.19799\n",
      "[700]\ttrain-mae:0.00295\tvalid-mae:0.19794\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.19792\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19790\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19789\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19788\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19788\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19788\n",
      "[1400]\ttrain-mae:0.00057\tvalid-mae:0.19788\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.19788\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19789\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19789\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19789\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19789\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19789\n",
      "  ğŸ” Fold MAE: 0.1979\n",
      "\n",
      "ğŸ” Seed 42 - Fold 15/20\n",
      "[0]\ttrain-mae:0.20360\tvalid-mae:0.20489\n",
      "[100]\ttrain-mae:0.10690\tvalid-mae:0.19433\n",
      "[200]\ttrain-mae:0.05618\tvalid-mae:0.19219\n",
      "[300]\ttrain-mae:0.03063\tvalid-mae:0.19139\n",
      "[400]\ttrain-mae:0.01739\tvalid-mae:0.19118\n",
      "[500]\ttrain-mae:0.00975\tvalid-mae:0.19102\n",
      "[600]\ttrain-mae:0.00547\tvalid-mae:0.19102\n",
      "[700]\ttrain-mae:0.00311\tvalid-mae:0.19105\n",
      "[800]\ttrain-mae:0.00176\tvalid-mae:0.19108\n",
      "[900]\ttrain-mae:0.00103\tvalid-mae:0.19110\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19109\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19109\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19109\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19109\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19109\n",
      "[1453]\ttrain-mae:0.00056\tvalid-mae:0.19109\n",
      "  ğŸ” Fold MAE: 0.1911\n",
      "\n",
      "ğŸ” Seed 42 - Fold 16/20\n",
      "[0]\ttrain-mae:0.20355\tvalid-mae:0.21024\n",
      "[100]\ttrain-mae:0.10476\tvalid-mae:0.20038\n",
      "[200]\ttrain-mae:0.05473\tvalid-mae:0.19737\n",
      "[300]\ttrain-mae:0.02925\tvalid-mae:0.19551\n",
      "[400]\ttrain-mae:0.01633\tvalid-mae:0.19429\n",
      "[500]\ttrain-mae:0.00914\tvalid-mae:0.19394\n",
      "[600]\ttrain-mae:0.00524\tvalid-mae:0.19375\n",
      "[700]\ttrain-mae:0.00303\tvalid-mae:0.19361\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.19354\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.19350\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.19347\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19347\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19347\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19347\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19347\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19346\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19346\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19346\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19346\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19346\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19346\n",
      "  ğŸ” Fold MAE: 0.1935\n",
      "\n",
      "ğŸ” Seed 42 - Fold 17/20\n",
      "[0]\ttrain-mae:0.20430\tvalid-mae:0.19212\n",
      "[100]\ttrain-mae:0.10794\tvalid-mae:0.18251\n",
      "[200]\ttrain-mae:0.05662\tvalid-mae:0.17961\n",
      "[300]\ttrain-mae:0.03030\tvalid-mae:0.17860\n",
      "[400]\ttrain-mae:0.01680\tvalid-mae:0.17826\n",
      "[500]\ttrain-mae:0.00933\tvalid-mae:0.17821\n",
      "[600]\ttrain-mae:0.00540\tvalid-mae:0.17822\n",
      "[700]\ttrain-mae:0.00307\tvalid-mae:0.17819\n",
      "[800]\ttrain-mae:0.00177\tvalid-mae:0.17818\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.17818\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.17818\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.17818\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.17818\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.17818\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.17818\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.17818\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.17818\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.17818\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.17818\n",
      "[1868]\ttrain-mae:0.00053\tvalid-mae:0.17818\n",
      "  ğŸ” Fold MAE: 0.1782\n",
      "\n",
      "ğŸ” Seed 42 - Fold 18/20\n",
      "[0]\ttrain-mae:0.20327\tvalid-mae:0.21099\n",
      "[100]\ttrain-mae:0.10629\tvalid-mae:0.20254\n",
      "[200]\ttrain-mae:0.05493\tvalid-mae:0.20031\n",
      "[300]\ttrain-mae:0.02910\tvalid-mae:0.19936\n",
      "[400]\ttrain-mae:0.01588\tvalid-mae:0.19910\n",
      "[500]\ttrain-mae:0.00905\tvalid-mae:0.19880\n",
      "[600]\ttrain-mae:0.00515\tvalid-mae:0.19887\n",
      "[700]\ttrain-mae:0.00304\tvalid-mae:0.19884\n",
      "[800]\ttrain-mae:0.00176\tvalid-mae:0.19881\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19880\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19879\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19879\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19879\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19879\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19879\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.19879\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19879\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19879\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19879\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19879\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.19879\n",
      "  ğŸ” Fold MAE: 0.1988\n",
      "\n",
      "ğŸ” Seed 42 - Fold 19/20\n",
      "[0]\ttrain-mae:0.20334\tvalid-mae:0.20787\n",
      "[100]\ttrain-mae:0.10190\tvalid-mae:0.20336\n",
      "[200]\ttrain-mae:0.05294\tvalid-mae:0.20308\n",
      "[300]\ttrain-mae:0.02775\tvalid-mae:0.20291\n",
      "[400]\ttrain-mae:0.01492\tvalid-mae:0.20317\n",
      "[500]\ttrain-mae:0.00812\tvalid-mae:0.20323\n",
      "[600]\ttrain-mae:0.00456\tvalid-mae:0.20332\n",
      "[700]\ttrain-mae:0.00266\tvalid-mae:0.20329\n",
      "[800]\ttrain-mae:0.00156\tvalid-mae:0.20330\n",
      "[900]\ttrain-mae:0.00096\tvalid-mae:0.20329\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.20330\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20330\n",
      "[1170]\ttrain-mae:0.00059\tvalid-mae:0.20330\n",
      "  ğŸ” Fold MAE: 0.2033\n",
      "\n",
      "ğŸ” Seed 42 - Fold 20/20\n",
      "[0]\ttrain-mae:0.20330\tvalid-mae:0.21430\n",
      "[100]\ttrain-mae:0.10465\tvalid-mae:0.20751\n",
      "[200]\ttrain-mae:0.05349\tvalid-mae:0.20456\n",
      "[300]\ttrain-mae:0.02885\tvalid-mae:0.20292\n",
      "[400]\ttrain-mae:0.01550\tvalid-mae:0.20200\n",
      "[500]\ttrain-mae:0.00867\tvalid-mae:0.20156\n",
      "[600]\ttrain-mae:0.00496\tvalid-mae:0.20130\n",
      "[700]\ttrain-mae:0.00287\tvalid-mae:0.20120\n",
      "[800]\ttrain-mae:0.00169\tvalid-mae:0.20111\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.20105\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.20103\n",
      "[1100]\ttrain-mae:0.00062\tvalid-mae:0.20103\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.20103\n",
      "[1300]\ttrain-mae:0.00058\tvalid-mae:0.20103\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20102\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.20103\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.20102\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.20102\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.20102\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.20102\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.20102\n",
      "  ğŸ” Fold MAE: 0.2010\n",
      "\n",
      "ğŸ§ª Seed 77 ì‹œì‘\n",
      "\n",
      "ğŸ” Seed 77 - Fold 1/20\n",
      "[0]\ttrain-mae:0.20283\tvalid-mae:0.21835\n",
      "[100]\ttrain-mae:0.10258\tvalid-mae:0.21064\n",
      "[200]\ttrain-mae:0.05274\tvalid-mae:0.20983\n",
      "[300]\ttrain-mae:0.02814\tvalid-mae:0.20923\n",
      "[400]\ttrain-mae:0.01545\tvalid-mae:0.20871\n",
      "[500]\ttrain-mae:0.00853\tvalid-mae:0.20863\n",
      "[600]\ttrain-mae:0.00478\tvalid-mae:0.20862\n",
      "[700]\ttrain-mae:0.00271\tvalid-mae:0.20860\n",
      "[800]\ttrain-mae:0.00159\tvalid-mae:0.20858\n",
      "[900]\ttrain-mae:0.00095\tvalid-mae:0.20857\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.20857\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20857\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20857\n",
      "[1300]\ttrain-mae:0.00055\tvalid-mae:0.20857\n",
      "[1400]\ttrain-mae:0.00054\tvalid-mae:0.20857\n",
      "[1500]\ttrain-mae:0.00054\tvalid-mae:0.20857\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.20857\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.20857\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.20857\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.20857\n",
      "[1907]\ttrain-mae:0.00053\tvalid-mae:0.20857\n",
      "  ğŸ” Fold MAE: 0.2086\n",
      "\n",
      "ğŸ” Seed 77 - Fold 2/20\n",
      "[0]\ttrain-mae:0.20282\tvalid-mae:0.22090\n",
      "[100]\ttrain-mae:0.10469\tvalid-mae:0.21483\n",
      "[200]\ttrain-mae:0.05530\tvalid-mae:0.21326\n",
      "[300]\ttrain-mae:0.02984\tvalid-mae:0.21293\n",
      "[400]\ttrain-mae:0.01663\tvalid-mae:0.21268\n",
      "[500]\ttrain-mae:0.00946\tvalid-mae:0.21255\n",
      "[600]\ttrain-mae:0.00548\tvalid-mae:0.21245\n",
      "[700]\ttrain-mae:0.00313\tvalid-mae:0.21247\n",
      "[800]\ttrain-mae:0.00179\tvalid-mae:0.21246\n",
      "[900]\ttrain-mae:0.00107\tvalid-mae:0.21246\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.21247\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.21247\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.21247\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.21248\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.21247\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.21247\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.21247\n",
      "[1602]\ttrain-mae:0.00055\tvalid-mae:0.21247\n",
      "  ğŸ” Fold MAE: 0.2125\n",
      "\n",
      "ğŸ” Seed 77 - Fold 3/20\n",
      "[0]\ttrain-mae:0.20419\tvalid-mae:0.19097\n",
      "[100]\ttrain-mae:0.10591\tvalid-mae:0.18567\n",
      "[200]\ttrain-mae:0.05477\tvalid-mae:0.18537\n",
      "[300]\ttrain-mae:0.02914\tvalid-mae:0.18576\n",
      "[400]\ttrain-mae:0.01570\tvalid-mae:0.18607\n",
      "[500]\ttrain-mae:0.00890\tvalid-mae:0.18617\n",
      "[600]\ttrain-mae:0.00516\tvalid-mae:0.18627\n",
      "[700]\ttrain-mae:0.00294\tvalid-mae:0.18631\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.18630\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.18631\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.18632\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.18632\n",
      "[1191]\ttrain-mae:0.00057\tvalid-mae:0.18632\n",
      "  ğŸ” Fold MAE: 0.1863\n",
      "\n",
      "ğŸ” Seed 77 - Fold 4/20\n",
      "[0]\ttrain-mae:0.20295\tvalid-mae:0.21656\n",
      "[100]\ttrain-mae:0.10857\tvalid-mae:0.21285\n",
      "[200]\ttrain-mae:0.05850\tvalid-mae:0.21192\n",
      "[300]\ttrain-mae:0.03169\tvalid-mae:0.21144\n",
      "[400]\ttrain-mae:0.01742\tvalid-mae:0.21094\n",
      "[500]\ttrain-mae:0.00984\tvalid-mae:0.21094\n",
      "[600]\ttrain-mae:0.00565\tvalid-mae:0.21084\n",
      "[700]\ttrain-mae:0.00325\tvalid-mae:0.21089\n",
      "[800]\ttrain-mae:0.00190\tvalid-mae:0.21089\n",
      "[900]\ttrain-mae:0.00111\tvalid-mae:0.21090\n",
      "[1000]\ttrain-mae:0.00071\tvalid-mae:0.21091\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.21091\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.21091\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.21091\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.21091\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.21091\n",
      "[1566]\ttrain-mae:0.00055\tvalid-mae:0.21091\n",
      "  ğŸ” Fold MAE: 0.2109\n",
      "\n",
      "ğŸ” Seed 77 - Fold 5/20\n",
      "[0]\ttrain-mae:0.20403\tvalid-mae:0.19569\n",
      "[100]\ttrain-mae:0.10211\tvalid-mae:0.18326\n",
      "[200]\ttrain-mae:0.05262\tvalid-mae:0.17933\n",
      "[300]\ttrain-mae:0.02766\tvalid-mae:0.17787\n",
      "[400]\ttrain-mae:0.01499\tvalid-mae:0.17735\n",
      "[500]\ttrain-mae:0.00841\tvalid-mae:0.17719\n",
      "[600]\ttrain-mae:0.00479\tvalid-mae:0.17710\n",
      "[700]\ttrain-mae:0.00283\tvalid-mae:0.17700\n",
      "[800]\ttrain-mae:0.00163\tvalid-mae:0.17699\n",
      "[900]\ttrain-mae:0.00097\tvalid-mae:0.17700\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.17700\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.17699\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.17699\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.17699\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.17699\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.17699\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.17699\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.17699\n",
      "[1785]\ttrain-mae:0.00055\tvalid-mae:0.17699\n",
      "  ğŸ” Fold MAE: 0.1770\n",
      "\n",
      "ğŸ” Seed 77 - Fold 6/20\n",
      "[0]\ttrain-mae:0.20429\tvalid-mae:0.19109\n",
      "[100]\ttrain-mae:0.10648\tvalid-mae:0.18400\n",
      "[200]\ttrain-mae:0.05624\tvalid-mae:0.18342\n",
      "[300]\ttrain-mae:0.03011\tvalid-mae:0.18304\n",
      "[400]\ttrain-mae:0.01653\tvalid-mae:0.18330\n",
      "[500]\ttrain-mae:0.00918\tvalid-mae:0.18360\n",
      "[600]\ttrain-mae:0.00518\tvalid-mae:0.18366\n",
      "[700]\ttrain-mae:0.00297\tvalid-mae:0.18368\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.18367\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.18368\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.18369\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.18369\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18369\n",
      "[1299]\ttrain-mae:0.00056\tvalid-mae:0.18369\n",
      "  ğŸ” Fold MAE: 0.1837\n",
      "\n",
      "ğŸ” Seed 77 - Fold 7/20\n",
      "[0]\ttrain-mae:0.20433\tvalid-mae:0.19250\n",
      "[100]\ttrain-mae:0.10352\tvalid-mae:0.18878\n",
      "[200]\ttrain-mae:0.05383\tvalid-mae:0.18864\n",
      "[300]\ttrain-mae:0.02885\tvalid-mae:0.18989\n",
      "[400]\ttrain-mae:0.01632\tvalid-mae:0.19024\n",
      "[500]\ttrain-mae:0.00905\tvalid-mae:0.19057\n",
      "[600]\ttrain-mae:0.00512\tvalid-mae:0.19070\n",
      "[700]\ttrain-mae:0.00298\tvalid-mae:0.19079\n",
      "[800]\ttrain-mae:0.00170\tvalid-mae:0.19079\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.19081\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19082\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19082\n",
      "[1176]\ttrain-mae:0.00058\tvalid-mae:0.19082\n",
      "  ğŸ” Fold MAE: 0.1908\n",
      "\n",
      "ğŸ” Seed 77 - Fold 8/20\n",
      "[0]\ttrain-mae:0.20376\tvalid-mae:0.20392\n",
      "[100]\ttrain-mae:0.10554\tvalid-mae:0.19853\n",
      "[200]\ttrain-mae:0.05534\tvalid-mae:0.19611\n",
      "[300]\ttrain-mae:0.02907\tvalid-mae:0.19441\n",
      "[400]\ttrain-mae:0.01630\tvalid-mae:0.19388\n",
      "[500]\ttrain-mae:0.00906\tvalid-mae:0.19361\n",
      "[600]\ttrain-mae:0.00502\tvalid-mae:0.19354\n",
      "[700]\ttrain-mae:0.00286\tvalid-mae:0.19347\n",
      "[800]\ttrain-mae:0.00169\tvalid-mae:0.19342\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.19341\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19340\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19339\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19339\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19339\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19339\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19339\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19339\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19339\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19339\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19339\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.19339\n",
      "  ğŸ” Fold MAE: 0.1934\n",
      "\n",
      "ğŸ” Seed 77 - Fold 9/20\n",
      "[0]\ttrain-mae:0.20375\tvalid-mae:0.20220\n",
      "[100]\ttrain-mae:0.10476\tvalid-mae:0.19041\n",
      "[200]\ttrain-mae:0.05468\tvalid-mae:0.18973\n",
      "[300]\ttrain-mae:0.02941\tvalid-mae:0.19001\n",
      "[400]\ttrain-mae:0.01549\tvalid-mae:0.19017\n",
      "[500]\ttrain-mae:0.00830\tvalid-mae:0.19037\n",
      "[600]\ttrain-mae:0.00465\tvalid-mae:0.19050\n",
      "[700]\ttrain-mae:0.00261\tvalid-mae:0.19064\n",
      "[800]\ttrain-mae:0.00152\tvalid-mae:0.19068\n",
      "[900]\ttrain-mae:0.00091\tvalid-mae:0.19069\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.19070\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.19070\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19070\n",
      "[1223]\ttrain-mae:0.00056\tvalid-mae:0.19070\n",
      "  ğŸ” Fold MAE: 0.1907\n",
      "\n",
      "ğŸ” Seed 77 - Fold 10/20\n",
      "[0]\ttrain-mae:0.20359\tvalid-mae:0.20731\n",
      "[100]\ttrain-mae:0.10013\tvalid-mae:0.20220\n",
      "[200]\ttrain-mae:0.05004\tvalid-mae:0.20162\n",
      "[300]\ttrain-mae:0.02546\tvalid-mae:0.20157\n",
      "[400]\ttrain-mae:0.01364\tvalid-mae:0.20175\n",
      "[500]\ttrain-mae:0.00764\tvalid-mae:0.20176\n",
      "[600]\ttrain-mae:0.00434\tvalid-mae:0.20184\n",
      "[700]\ttrain-mae:0.00253\tvalid-mae:0.20187\n",
      "[800]\ttrain-mae:0.00148\tvalid-mae:0.20188\n",
      "[900]\ttrain-mae:0.00092\tvalid-mae:0.20187\n",
      "[1000]\ttrain-mae:0.00064\tvalid-mae:0.20186\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.20186\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20186\n",
      "[1217]\ttrain-mae:0.00057\tvalid-mae:0.20186\n",
      "  ğŸ” Fold MAE: 0.2019\n",
      "\n",
      "ğŸ” Seed 77 - Fold 11/20\n",
      "[0]\ttrain-mae:0.20357\tvalid-mae:0.20043\n",
      "[100]\ttrain-mae:0.10522\tvalid-mae:0.19235\n",
      "[200]\ttrain-mae:0.05538\tvalid-mae:0.19211\n",
      "[300]\ttrain-mae:0.02918\tvalid-mae:0.19210\n",
      "[400]\ttrain-mae:0.01568\tvalid-mae:0.19185\n",
      "[500]\ttrain-mae:0.00875\tvalid-mae:0.19189\n",
      "[600]\ttrain-mae:0.00510\tvalid-mae:0.19189\n",
      "[700]\ttrain-mae:0.00300\tvalid-mae:0.19195\n",
      "[800]\ttrain-mae:0.00176\tvalid-mae:0.19196\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.19198\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.19198\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19199\n",
      "[1149]\ttrain-mae:0.00059\tvalid-mae:0.19199\n",
      "  ğŸ” Fold MAE: 0.1920\n",
      "\n",
      "ğŸ” Seed 77 - Fold 12/20\n",
      "[0]\ttrain-mae:0.20440\tvalid-mae:0.19675\n",
      "[100]\ttrain-mae:0.10571\tvalid-mae:0.18570\n",
      "[200]\ttrain-mae:0.05481\tvalid-mae:0.18330\n",
      "[300]\ttrain-mae:0.02870\tvalid-mae:0.18243\n",
      "[400]\ttrain-mae:0.01560\tvalid-mae:0.18238\n",
      "[500]\ttrain-mae:0.00852\tvalid-mae:0.18219\n",
      "[600]\ttrain-mae:0.00479\tvalid-mae:0.18202\n",
      "[700]\ttrain-mae:0.00282\tvalid-mae:0.18198\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.18195\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.18193\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.18192\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18192\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.18192\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18192\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18192\n",
      "[1500]\ttrain-mae:0.00054\tvalid-mae:0.18192\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.18192\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.18192\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18192\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.18192\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.18192\n",
      "  ğŸ” Fold MAE: 0.1819\n",
      "\n",
      "ğŸ” Seed 77 - Fold 13/20\n",
      "[0]\ttrain-mae:0.20350\tvalid-mae:0.20449\n",
      "[100]\ttrain-mae:0.10665\tvalid-mae:0.19643\n",
      "[200]\ttrain-mae:0.05597\tvalid-mae:0.19321\n",
      "[300]\ttrain-mae:0.02948\tvalid-mae:0.19316\n",
      "[400]\ttrain-mae:0.01610\tvalid-mae:0.19337\n",
      "[500]\ttrain-mae:0.00907\tvalid-mae:0.19350\n",
      "[600]\ttrain-mae:0.00514\tvalid-mae:0.19356\n",
      "[700]\ttrain-mae:0.00300\tvalid-mae:0.19355\n",
      "[800]\ttrain-mae:0.00173\tvalid-mae:0.19356\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.19357\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19359\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19359\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19359\n",
      "[1222]\ttrain-mae:0.00057\tvalid-mae:0.19359\n",
      "  ğŸ” Fold MAE: 0.1936\n",
      "\n",
      "ğŸ” Seed 77 - Fold 14/20\n",
      "[0]\ttrain-mae:0.20292\tvalid-mae:0.21619\n",
      "[100]\ttrain-mae:0.10270\tvalid-mae:0.20702\n",
      "[200]\ttrain-mae:0.05186\tvalid-mae:0.20424\n",
      "[300]\ttrain-mae:0.02660\tvalid-mae:0.20294\n",
      "[400]\ttrain-mae:0.01434\tvalid-mae:0.20248\n",
      "[500]\ttrain-mae:0.00810\tvalid-mae:0.20231\n",
      "[600]\ttrain-mae:0.00461\tvalid-mae:0.20221\n",
      "[700]\ttrain-mae:0.00265\tvalid-mae:0.20218\n",
      "[800]\ttrain-mae:0.00154\tvalid-mae:0.20216\n",
      "[900]\ttrain-mae:0.00094\tvalid-mae:0.20216\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.20216\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20216\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20216\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.20216\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20216\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20216\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.20216\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.20216\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.20216\n",
      "[1883]\ttrain-mae:0.00053\tvalid-mae:0.20216\n",
      "  ğŸ” Fold MAE: 0.2022\n",
      "\n",
      "ğŸ” Seed 77 - Fold 15/20\n",
      "[0]\ttrain-mae:0.20293\tvalid-mae:0.21631\n",
      "[100]\ttrain-mae:0.10639\tvalid-mae:0.20904\n",
      "[200]\ttrain-mae:0.05559\tvalid-mae:0.20711\n",
      "[300]\ttrain-mae:0.03016\tvalid-mae:0.20614\n",
      "[400]\ttrain-mae:0.01636\tvalid-mae:0.20618\n",
      "[500]\ttrain-mae:0.00922\tvalid-mae:0.20610\n",
      "[600]\ttrain-mae:0.00522\tvalid-mae:0.20606\n",
      "[700]\ttrain-mae:0.00299\tvalid-mae:0.20601\n",
      "[800]\ttrain-mae:0.00177\tvalid-mae:0.20603\n",
      "[900]\ttrain-mae:0.00106\tvalid-mae:0.20605\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.20604\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20603\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20603\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.20603\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20604\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20604\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.20604\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.20604\n",
      "[1711]\ttrain-mae:0.00055\tvalid-mae:0.20604\n",
      "  ğŸ” Fold MAE: 0.2060\n",
      "\n",
      "ğŸ” Seed 77 - Fold 16/20\n",
      "[0]\ttrain-mae:0.20427\tvalid-mae:0.19179\n",
      "[100]\ttrain-mae:0.10365\tvalid-mae:0.18863\n",
      "[200]\ttrain-mae:0.05366\tvalid-mae:0.18917\n",
      "[300]\ttrain-mae:0.02863\tvalid-mae:0.18926\n",
      "[400]\ttrain-mae:0.01578\tvalid-mae:0.18921\n",
      "[500]\ttrain-mae:0.00888\tvalid-mae:0.18905\n",
      "[600]\ttrain-mae:0.00505\tvalid-mae:0.18887\n",
      "[700]\ttrain-mae:0.00297\tvalid-mae:0.18888\n",
      "[800]\ttrain-mae:0.00172\tvalid-mae:0.18885\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.18883\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.18883\n",
      "[1097]\ttrain-mae:0.00060\tvalid-mae:0.18883\n",
      "  ğŸ” Fold MAE: 0.1888\n",
      "\n",
      "ğŸ” Seed 77 - Fold 17/20\n",
      "[0]\ttrain-mae:0.20371\tvalid-mae:0.20079\n",
      "[100]\ttrain-mae:0.10754\tvalid-mae:0.19276\n",
      "[200]\ttrain-mae:0.05705\tvalid-mae:0.19180\n",
      "[300]\ttrain-mae:0.03065\tvalid-mae:0.19201\n",
      "[400]\ttrain-mae:0.01700\tvalid-mae:0.19218\n",
      "[500]\ttrain-mae:0.00938\tvalid-mae:0.19209\n",
      "[600]\ttrain-mae:0.00547\tvalid-mae:0.19219\n",
      "[700]\ttrain-mae:0.00315\tvalid-mae:0.19214\n",
      "[800]\ttrain-mae:0.00183\tvalid-mae:0.19216\n",
      "[900]\ttrain-mae:0.00109\tvalid-mae:0.19218\n",
      "[1000]\ttrain-mae:0.00071\tvalid-mae:0.19217\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19217\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19217\n",
      "[1205]\ttrain-mae:0.00058\tvalid-mae:0.19217\n",
      "  ğŸ” Fold MAE: 0.1922\n",
      "\n",
      "ğŸ” Seed 77 - Fold 18/20\n",
      "[0]\ttrain-mae:0.20347\tvalid-mae:0.20730\n",
      "[100]\ttrain-mae:0.10329\tvalid-mae:0.19458\n",
      "[200]\ttrain-mae:0.05352\tvalid-mae:0.19216\n",
      "[300]\ttrain-mae:0.02839\tvalid-mae:0.19105\n",
      "[400]\ttrain-mae:0.01627\tvalid-mae:0.19077\n",
      "[500]\ttrain-mae:0.00914\tvalid-mae:0.19075\n",
      "[600]\ttrain-mae:0.00524\tvalid-mae:0.19062\n",
      "[700]\ttrain-mae:0.00304\tvalid-mae:0.19062\n",
      "[800]\ttrain-mae:0.00178\tvalid-mae:0.19060\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19058\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19057\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19057\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19057\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19057\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19057\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19057\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19057\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19057\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19057\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19057\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19057\n",
      "  ğŸ” Fold MAE: 0.1906\n",
      "\n",
      "ğŸ” Seed 77 - Fold 19/20\n",
      "[0]\ttrain-mae:0.20319\tvalid-mae:0.21089\n",
      "[100]\ttrain-mae:0.10304\tvalid-mae:0.20883\n",
      "[200]\ttrain-mae:0.05343\tvalid-mae:0.21009\n",
      "[300]\ttrain-mae:0.02807\tvalid-mae:0.21121\n",
      "[400]\ttrain-mae:0.01524\tvalid-mae:0.21156\n",
      "[500]\ttrain-mae:0.00857\tvalid-mae:0.21172\n",
      "[600]\ttrain-mae:0.00485\tvalid-mae:0.21179\n",
      "[700]\ttrain-mae:0.00278\tvalid-mae:0.21184\n",
      "[800]\ttrain-mae:0.00162\tvalid-mae:0.21184\n",
      "[900]\ttrain-mae:0.00093\tvalid-mae:0.21183\n",
      "[1000]\ttrain-mae:0.00063\tvalid-mae:0.21184\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.21184\n",
      "[1133]\ttrain-mae:0.00058\tvalid-mae:0.21184\n",
      "  ğŸ” Fold MAE: 0.2118\n",
      "\n",
      "ğŸ” Seed 77 - Fold 20/20\n",
      "[0]\ttrain-mae:0.20301\tvalid-mae:0.21233\n",
      "[100]\ttrain-mae:0.10030\tvalid-mae:0.20646\n",
      "[200]\ttrain-mae:0.05103\tvalid-mae:0.20418\n",
      "[300]\ttrain-mae:0.02751\tvalid-mae:0.20336\n",
      "[400]\ttrain-mae:0.01537\tvalid-mae:0.20304\n",
      "[500]\ttrain-mae:0.00861\tvalid-mae:0.20297\n",
      "[600]\ttrain-mae:0.00500\tvalid-mae:0.20288\n",
      "[700]\ttrain-mae:0.00286\tvalid-mae:0.20282\n",
      "[800]\ttrain-mae:0.00175\tvalid-mae:0.20278\n",
      "[900]\ttrain-mae:0.00106\tvalid-mae:0.20275\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.20273\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20273\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20273\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.20273\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.20273\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20273\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.20273\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.20273\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.20273\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.20273\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.20273\n",
      "  ğŸ” Fold MAE: 0.2027\n",
      "\n",
      "ğŸ§ª Seed 123 ì‹œì‘\n",
      "\n",
      "ğŸ” Seed 123 - Fold 1/20\n",
      "[0]\ttrain-mae:0.20368\tvalid-mae:0.21062\n",
      "[100]\ttrain-mae:0.10602\tvalid-mae:0.20496\n",
      "[200]\ttrain-mae:0.05617\tvalid-mae:0.20238\n",
      "[300]\ttrain-mae:0.03058\tvalid-mae:0.20184\n",
      "[400]\ttrain-mae:0.01677\tvalid-mae:0.20150\n",
      "[500]\ttrain-mae:0.00939\tvalid-mae:0.20140\n",
      "[600]\ttrain-mae:0.00537\tvalid-mae:0.20142\n",
      "[700]\ttrain-mae:0.00305\tvalid-mae:0.20141\n",
      "[800]\ttrain-mae:0.00178\tvalid-mae:0.20141\n",
      "[900]\ttrain-mae:0.00109\tvalid-mae:0.20141\n",
      "[1000]\ttrain-mae:0.00071\tvalid-mae:0.20140\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.20139\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.20139\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.20139\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.20139\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20139\n",
      "[1511]\ttrain-mae:0.00055\tvalid-mae:0.20139\n",
      "  ğŸ” Fold MAE: 0.2014\n",
      "\n",
      "ğŸ” Seed 123 - Fold 2/20\n",
      "[0]\ttrain-mae:0.20362\tvalid-mae:0.20044\n",
      "[100]\ttrain-mae:0.10405\tvalid-mae:0.19192\n",
      "[200]\ttrain-mae:0.05311\tvalid-mae:0.19062\n",
      "[300]\ttrain-mae:0.02807\tvalid-mae:0.18963\n",
      "[400]\ttrain-mae:0.01564\tvalid-mae:0.18947\n",
      "[500]\ttrain-mae:0.00914\tvalid-mae:0.18946\n",
      "[600]\ttrain-mae:0.00513\tvalid-mae:0.18943\n",
      "[700]\ttrain-mae:0.00299\tvalid-mae:0.18939\n",
      "[800]\ttrain-mae:0.00174\tvalid-mae:0.18938\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.18937\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.18937\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18936\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.18936\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18936\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18936\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.18936\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.18936\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.18936\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18936\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.18936\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.18936\n",
      "  ğŸ” Fold MAE: 0.1894\n",
      "\n",
      "ğŸ” Seed 123 - Fold 3/20\n",
      "[0]\ttrain-mae:0.20368\tvalid-mae:0.20498\n",
      "[100]\ttrain-mae:0.10338\tvalid-mae:0.19662\n",
      "[200]\ttrain-mae:0.05429\tvalid-mae:0.19455\n",
      "[300]\ttrain-mae:0.02992\tvalid-mae:0.19396\n",
      "[400]\ttrain-mae:0.01626\tvalid-mae:0.19381\n",
      "[500]\ttrain-mae:0.00906\tvalid-mae:0.19379\n",
      "[600]\ttrain-mae:0.00512\tvalid-mae:0.19368\n",
      "[700]\ttrain-mae:0.00309\tvalid-mae:0.19368\n",
      "[800]\ttrain-mae:0.00181\tvalid-mae:0.19368\n",
      "[900]\ttrain-mae:0.00108\tvalid-mae:0.19366\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.19367\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19367\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19367\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19367\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19367\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19367\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19367\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19367\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19367\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19367\n",
      "[1942]\ttrain-mae:0.00054\tvalid-mae:0.19367\n",
      "  ğŸ” Fold MAE: 0.1937\n",
      "\n",
      "ğŸ” Seed 123 - Fold 4/20\n",
      "[0]\ttrain-mae:0.20363\tvalid-mae:0.20451\n",
      "[100]\ttrain-mae:0.10310\tvalid-mae:0.20209\n",
      "[200]\ttrain-mae:0.05342\tvalid-mae:0.20306\n",
      "[300]\ttrain-mae:0.02874\tvalid-mae:0.20398\n",
      "[400]\ttrain-mae:0.01548\tvalid-mae:0.20449\n",
      "[500]\ttrain-mae:0.00880\tvalid-mae:0.20466\n",
      "[600]\ttrain-mae:0.00516\tvalid-mae:0.20475\n",
      "[700]\ttrain-mae:0.00300\tvalid-mae:0.20486\n",
      "[800]\ttrain-mae:0.00172\tvalid-mae:0.20492\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.20492\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.20493\n",
      "[1066]\ttrain-mae:0.00061\tvalid-mae:0.20493\n",
      "  ğŸ” Fold MAE: 0.2049\n",
      "\n",
      "ğŸ” Seed 123 - Fold 5/20\n",
      "[0]\ttrain-mae:0.20437\tvalid-mae:0.18985\n",
      "[100]\ttrain-mae:0.10377\tvalid-mae:0.18263\n",
      "[200]\ttrain-mae:0.05345\tvalid-mae:0.17948\n",
      "[300]\ttrain-mae:0.02872\tvalid-mae:0.17844\n",
      "[400]\ttrain-mae:0.01547\tvalid-mae:0.17788\n",
      "[500]\ttrain-mae:0.00862\tvalid-mae:0.17766\n",
      "[600]\ttrain-mae:0.00501\tvalid-mae:0.17745\n",
      "[700]\ttrain-mae:0.00289\tvalid-mae:0.17737\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.17734\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.17732\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.17731\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.17731\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.17731\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.17731\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.17731\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.17731\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.17731\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.17731\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.17731\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.17731\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.17731\n",
      "  ğŸ” Fold MAE: 0.1773\n",
      "\n",
      "ğŸ” Seed 123 - Fold 6/20\n",
      "[0]\ttrain-mae:0.20346\tvalid-mae:0.20901\n",
      "[100]\ttrain-mae:0.10591\tvalid-mae:0.20737\n",
      "[200]\ttrain-mae:0.05481\tvalid-mae:0.20728\n",
      "[300]\ttrain-mae:0.02880\tvalid-mae:0.20727\n",
      "[400]\ttrain-mae:0.01573\tvalid-mae:0.20760\n",
      "[500]\ttrain-mae:0.00860\tvalid-mae:0.20776\n",
      "[600]\ttrain-mae:0.00501\tvalid-mae:0.20770\n",
      "[700]\ttrain-mae:0.00290\tvalid-mae:0.20772\n",
      "[800]\ttrain-mae:0.00167\tvalid-mae:0.20772\n",
      "[900]\ttrain-mae:0.00099\tvalid-mae:0.20773\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.20773\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.20773\n",
      "[1151]\ttrain-mae:0.00058\tvalid-mae:0.20773\n",
      "  ğŸ” Fold MAE: 0.2077\n",
      "\n",
      "ğŸ” Seed 123 - Fold 7/20\n",
      "[0]\ttrain-mae:0.20329\tvalid-mae:0.20522\n",
      "[100]\ttrain-mae:0.10442\tvalid-mae:0.19654\n",
      "[200]\ttrain-mae:0.05355\tvalid-mae:0.19419\n",
      "[300]\ttrain-mae:0.02874\tvalid-mae:0.19360\n",
      "[400]\ttrain-mae:0.01518\tvalid-mae:0.19325\n",
      "[500]\ttrain-mae:0.00851\tvalid-mae:0.19285\n",
      "[600]\ttrain-mae:0.00485\tvalid-mae:0.19275\n",
      "[700]\ttrain-mae:0.00282\tvalid-mae:0.19263\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.19256\n",
      "[900]\ttrain-mae:0.00099\tvalid-mae:0.19254\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19252\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19252\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19252\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19252\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19252\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.19252\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19252\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19252\n",
      "[1800]\ttrain-mae:0.00055\tvalid-mae:0.19252\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19252\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19252\n",
      "  ğŸ” Fold MAE: 0.1925\n",
      "\n",
      "ğŸ” Seed 123 - Fold 8/20\n",
      "[0]\ttrain-mae:0.20384\tvalid-mae:0.19914\n",
      "[100]\ttrain-mae:0.10442\tvalid-mae:0.19324\n",
      "[200]\ttrain-mae:0.05490\tvalid-mae:0.19257\n",
      "[300]\ttrain-mae:0.02949\tvalid-mae:0.19344\n",
      "[400]\ttrain-mae:0.01641\tvalid-mae:0.19380\n",
      "[500]\ttrain-mae:0.00915\tvalid-mae:0.19385\n",
      "[600]\ttrain-mae:0.00515\tvalid-mae:0.19392\n",
      "[700]\ttrain-mae:0.00299\tvalid-mae:0.19401\n",
      "[800]\ttrain-mae:0.00176\tvalid-mae:0.19406\n",
      "[900]\ttrain-mae:0.00108\tvalid-mae:0.19407\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.19407\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19408\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19408\n",
      "[1204]\ttrain-mae:0.00058\tvalid-mae:0.19408\n",
      "  ğŸ” Fold MAE: 0.1941\n",
      "\n",
      "ğŸ” Seed 123 - Fold 9/20\n",
      "[0]\ttrain-mae:0.20296\tvalid-mae:0.21809\n",
      "[100]\ttrain-mae:0.10309\tvalid-mae:0.20977\n",
      "[200]\ttrain-mae:0.05360\tvalid-mae:0.20671\n",
      "[300]\ttrain-mae:0.02840\tvalid-mae:0.20567\n",
      "[400]\ttrain-mae:0.01547\tvalid-mae:0.20518\n",
      "[500]\ttrain-mae:0.00844\tvalid-mae:0.20505\n",
      "[600]\ttrain-mae:0.00468\tvalid-mae:0.20501\n",
      "[700]\ttrain-mae:0.00276\tvalid-mae:0.20501\n",
      "[800]\ttrain-mae:0.00161\tvalid-mae:0.20499\n",
      "[900]\ttrain-mae:0.00095\tvalid-mae:0.20500\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.20500\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20500\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20500\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.20501\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20501\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20501\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.20501\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.20501\n",
      "[1789]\ttrain-mae:0.00054\tvalid-mae:0.20501\n",
      "  ğŸ” Fold MAE: 0.2050\n",
      "\n",
      "ğŸ” Seed 123 - Fold 10/20\n",
      "[0]\ttrain-mae:0.20403\tvalid-mae:0.19644\n",
      "[100]\ttrain-mae:0.10422\tvalid-mae:0.18369\n",
      "[200]\ttrain-mae:0.05335\tvalid-mae:0.18023\n",
      "[300]\ttrain-mae:0.02808\tvalid-mae:0.17915\n",
      "[400]\ttrain-mae:0.01552\tvalid-mae:0.17893\n",
      "[500]\ttrain-mae:0.00869\tvalid-mae:0.17874\n",
      "[600]\ttrain-mae:0.00492\tvalid-mae:0.17855\n",
      "[700]\ttrain-mae:0.00285\tvalid-mae:0.17854\n",
      "[800]\ttrain-mae:0.00167\tvalid-mae:0.17852\n",
      "[900]\ttrain-mae:0.00099\tvalid-mae:0.17850\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.17850\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.17849\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.17849\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.17849\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.17849\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.17849\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.17849\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.17849\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.17849\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.17849\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.17849\n",
      "  ğŸ” Fold MAE: 0.1785\n",
      "\n",
      "ğŸ” Seed 123 - Fold 11/20\n",
      "[0]\ttrain-mae:0.20309\tvalid-mae:0.21092\n",
      "[100]\ttrain-mae:0.10231\tvalid-mae:0.20756\n",
      "[200]\ttrain-mae:0.05275\tvalid-mae:0.20856\n",
      "[300]\ttrain-mae:0.02800\tvalid-mae:0.20911\n",
      "[400]\ttrain-mae:0.01529\tvalid-mae:0.20935\n",
      "[500]\ttrain-mae:0.00851\tvalid-mae:0.20940\n",
      "[600]\ttrain-mae:0.00475\tvalid-mae:0.20946\n",
      "[700]\ttrain-mae:0.00270\tvalid-mae:0.20951\n",
      "[800]\ttrain-mae:0.00156\tvalid-mae:0.20952\n",
      "[900]\ttrain-mae:0.00092\tvalid-mae:0.20952\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.20952\n",
      "[1058]\ttrain-mae:0.00061\tvalid-mae:0.20952\n",
      "  ğŸ” Fold MAE: 0.2095\n",
      "\n",
      "ğŸ” Seed 123 - Fold 12/20\n",
      "[0]\ttrain-mae:0.20312\tvalid-mae:0.21206\n",
      "[100]\ttrain-mae:0.10217\tvalid-mae:0.20810\n",
      "[200]\ttrain-mae:0.05194\tvalid-mae:0.20770\n",
      "[300]\ttrain-mae:0.02719\tvalid-mae:0.20857\n",
      "[400]\ttrain-mae:0.01453\tvalid-mae:0.20864\n",
      "[500]\ttrain-mae:0.00802\tvalid-mae:0.20904\n",
      "[600]\ttrain-mae:0.00456\tvalid-mae:0.20914\n",
      "[700]\ttrain-mae:0.00262\tvalid-mae:0.20920\n",
      "[800]\ttrain-mae:0.00155\tvalid-mae:0.20922\n",
      "[900]\ttrain-mae:0.00092\tvalid-mae:0.20922\n",
      "[1000]\ttrain-mae:0.00064\tvalid-mae:0.20923\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.20923\n",
      "[1122]\ttrain-mae:0.00059\tvalid-mae:0.20923\n",
      "  ğŸ” Fold MAE: 0.2092\n",
      "\n",
      "ğŸ” Seed 123 - Fold 13/20\n",
      "[0]\ttrain-mae:0.20420\tvalid-mae:0.19413\n",
      "[100]\ttrain-mae:0.10800\tvalid-mae:0.19249\n",
      "[200]\ttrain-mae:0.05733\tvalid-mae:0.19241\n",
      "[300]\ttrain-mae:0.03053\tvalid-mae:0.19241\n",
      "[400]\ttrain-mae:0.01650\tvalid-mae:0.19220\n",
      "[500]\ttrain-mae:0.00921\tvalid-mae:0.19207\n",
      "[600]\ttrain-mae:0.00520\tvalid-mae:0.19196\n",
      "[700]\ttrain-mae:0.00301\tvalid-mae:0.19198\n",
      "[800]\ttrain-mae:0.00176\tvalid-mae:0.19193\n",
      "[900]\ttrain-mae:0.00106\tvalid-mae:0.19192\n",
      "[1000]\ttrain-mae:0.00071\tvalid-mae:0.19192\n",
      "[1047]\ttrain-mae:0.00065\tvalid-mae:0.19192\n",
      "  ğŸ” Fold MAE: 0.1919\n",
      "\n",
      "ğŸ” Seed 123 - Fold 14/20\n",
      "[0]\ttrain-mae:0.20317\tvalid-mae:0.20743\n",
      "[100]\ttrain-mae:0.10272\tvalid-mae:0.19700\n",
      "[200]\ttrain-mae:0.05312\tvalid-mae:0.19484\n",
      "[300]\ttrain-mae:0.02861\tvalid-mae:0.19404\n",
      "[400]\ttrain-mae:0.01602\tvalid-mae:0.19333\n",
      "[500]\ttrain-mae:0.00886\tvalid-mae:0.19304\n",
      "[600]\ttrain-mae:0.00501\tvalid-mae:0.19287\n",
      "[700]\ttrain-mae:0.00291\tvalid-mae:0.19278\n",
      "[800]\ttrain-mae:0.00173\tvalid-mae:0.19273\n",
      "[900]\ttrain-mae:0.00104\tvalid-mae:0.19271\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.19270\n",
      "[1100]\ttrain-mae:0.00062\tvalid-mae:0.19270\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19269\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19269\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19269\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19269\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19269\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19269\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.19269\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.19269\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.19269\n",
      "  ğŸ” Fold MAE: 0.1927\n",
      "\n",
      "ğŸ” Seed 123 - Fold 15/20\n",
      "[0]\ttrain-mae:0.20312\tvalid-mae:0.21274\n",
      "[100]\ttrain-mae:0.10361\tvalid-mae:0.20567\n",
      "[200]\ttrain-mae:0.05332\tvalid-mae:0.20467\n",
      "[300]\ttrain-mae:0.02894\tvalid-mae:0.20457\n",
      "[400]\ttrain-mae:0.01593\tvalid-mae:0.20451\n",
      "[500]\ttrain-mae:0.00880\tvalid-mae:0.20460\n",
      "[600]\ttrain-mae:0.00505\tvalid-mae:0.20457\n",
      "[700]\ttrain-mae:0.00294\tvalid-mae:0.20451\n",
      "[800]\ttrain-mae:0.00176\tvalid-mae:0.20452\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.20450\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.20450\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.20450\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20450\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.20450\n",
      "[1351]\ttrain-mae:0.00056\tvalid-mae:0.20450\n",
      "  ğŸ” Fold MAE: 0.2045\n",
      "\n",
      "ğŸ” Seed 123 - Fold 16/20\n",
      "[0]\ttrain-mae:0.20291\tvalid-mae:0.21597\n",
      "[100]\ttrain-mae:0.10355\tvalid-mae:0.20564\n",
      "[200]\ttrain-mae:0.05404\tvalid-mae:0.20354\n",
      "[300]\ttrain-mae:0.02876\tvalid-mae:0.20252\n",
      "[400]\ttrain-mae:0.01536\tvalid-mae:0.20202\n",
      "[500]\ttrain-mae:0.00876\tvalid-mae:0.20198\n",
      "[600]\ttrain-mae:0.00504\tvalid-mae:0.20190\n",
      "[700]\ttrain-mae:0.00292\tvalid-mae:0.20182\n",
      "[800]\ttrain-mae:0.00173\tvalid-mae:0.20181\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.20178\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.20177\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20177\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.20177\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.20177\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20177\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.20177\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.20177\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.20177\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.20177\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.20177\n",
      "[1923]\ttrain-mae:0.00054\tvalid-mae:0.20177\n",
      "  ğŸ” Fold MAE: 0.2018\n",
      "\n",
      "ğŸ” Seed 123 - Fold 17/20\n",
      "[0]\ttrain-mae:0.20342\tvalid-mae:0.20811\n",
      "[100]\ttrain-mae:0.10565\tvalid-mae:0.19930\n",
      "[200]\ttrain-mae:0.05536\tvalid-mae:0.19768\n",
      "[300]\ttrain-mae:0.03040\tvalid-mae:0.19823\n",
      "[400]\ttrain-mae:0.01675\tvalid-mae:0.19887\n",
      "[500]\ttrain-mae:0.00926\tvalid-mae:0.19921\n",
      "[600]\ttrain-mae:0.00534\tvalid-mae:0.19941\n",
      "[700]\ttrain-mae:0.00304\tvalid-mae:0.19951\n",
      "[800]\ttrain-mae:0.00173\tvalid-mae:0.19954\n",
      "[900]\ttrain-mae:0.00103\tvalid-mae:0.19957\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19958\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19958\n",
      "[1165]\ttrain-mae:0.00059\tvalid-mae:0.19959\n",
      "  ğŸ” Fold MAE: 0.1996\n",
      "\n",
      "ğŸ” Seed 123 - Fold 18/20\n",
      "[0]\ttrain-mae:0.20445\tvalid-mae:0.18777\n",
      "[100]\ttrain-mae:0.10561\tvalid-mae:0.17987\n",
      "[200]\ttrain-mae:0.05590\tvalid-mae:0.17910\n",
      "[300]\ttrain-mae:0.03019\tvalid-mae:0.17995\n",
      "[400]\ttrain-mae:0.01692\tvalid-mae:0.18021\n",
      "[500]\ttrain-mae:0.00950\tvalid-mae:0.18038\n",
      "[600]\ttrain-mae:0.00527\tvalid-mae:0.18057\n",
      "[700]\ttrain-mae:0.00293\tvalid-mae:0.18072\n",
      "[800]\ttrain-mae:0.00163\tvalid-mae:0.18077\n",
      "[900]\ttrain-mae:0.00096\tvalid-mae:0.18080\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.18082\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.18082\n",
      "[1131]\ttrain-mae:0.00059\tvalid-mae:0.18082\n",
      "  ğŸ” Fold MAE: 0.1808\n",
      "\n",
      "ğŸ” Seed 123 - Fold 19/20\n",
      "[0]\ttrain-mae:0.20329\tvalid-mae:0.20715\n",
      "[100]\ttrain-mae:0.10272\tvalid-mae:0.20071\n",
      "[200]\ttrain-mae:0.05283\tvalid-mae:0.19882\n",
      "[300]\ttrain-mae:0.02798\tvalid-mae:0.19780\n",
      "[400]\ttrain-mae:0.01515\tvalid-mae:0.19768\n",
      "[500]\ttrain-mae:0.00837\tvalid-mae:0.19768\n",
      "[600]\ttrain-mae:0.00481\tvalid-mae:0.19751\n",
      "[700]\ttrain-mae:0.00281\tvalid-mae:0.19746\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.19744\n",
      "[900]\ttrain-mae:0.00098\tvalid-mae:0.19742\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19742\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19742\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19742\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19742\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19742\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19742\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19742\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19742\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19742\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.19742\n",
      "[1949]\ttrain-mae:0.00053\tvalid-mae:0.19742\n",
      "  ğŸ” Fold MAE: 0.1974\n",
      "\n",
      "ğŸ” Seed 123 - Fold 20/20\n",
      "[0]\ttrain-mae:0.20361\tvalid-mae:0.20265\n",
      "[100]\ttrain-mae:0.10481\tvalid-mae:0.19400\n",
      "[200]\ttrain-mae:0.05348\tvalid-mae:0.19216\n",
      "[300]\ttrain-mae:0.02870\tvalid-mae:0.19214\n",
      "[400]\ttrain-mae:0.01565\tvalid-mae:0.19212\n",
      "[500]\ttrain-mae:0.00869\tvalid-mae:0.19222\n",
      "[600]\ttrain-mae:0.00492\tvalid-mae:0.19234\n",
      "[700]\ttrain-mae:0.00280\tvalid-mae:0.19237\n",
      "[800]\ttrain-mae:0.00162\tvalid-mae:0.19242\n",
      "[900]\ttrain-mae:0.00097\tvalid-mae:0.19246\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19246\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.19247\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19247\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19247\n",
      "[1361]\ttrain-mae:0.00056\tvalid-mae:0.19247\n",
      "  ğŸ” Fold MAE: 0.1925\n",
      "\n",
      "ğŸ§ª Seed 999 ì‹œì‘\n",
      "\n",
      "ğŸ” Seed 999 - Fold 1/20\n",
      "[0]\ttrain-mae:0.20340\tvalid-mae:0.20905\n",
      "[100]\ttrain-mae:0.10635\tvalid-mae:0.19107\n",
      "[200]\ttrain-mae:0.05800\tvalid-mae:0.18503\n",
      "[300]\ttrain-mae:0.03137\tvalid-mae:0.18320\n",
      "[400]\ttrain-mae:0.01708\tvalid-mae:0.18233\n",
      "[500]\ttrain-mae:0.00976\tvalid-mae:0.18170\n",
      "[600]\ttrain-mae:0.00551\tvalid-mae:0.18149\n",
      "[700]\ttrain-mae:0.00316\tvalid-mae:0.18139\n",
      "[800]\ttrain-mae:0.00183\tvalid-mae:0.18131\n",
      "[900]\ttrain-mae:0.00108\tvalid-mae:0.18126\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.18124\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18124\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.18124\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18124\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18124\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.18124\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.18124\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.18124\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18124\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.18124\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.18124\n",
      "  ğŸ” Fold MAE: 0.1812\n",
      "\n",
      "ğŸ” Seed 999 - Fold 2/20\n",
      "[0]\ttrain-mae:0.20411\tvalid-mae:0.19805\n",
      "[100]\ttrain-mae:0.10529\tvalid-mae:0.18983\n",
      "[200]\ttrain-mae:0.05467\tvalid-mae:0.18810\n",
      "[300]\ttrain-mae:0.02893\tvalid-mae:0.18768\n",
      "[400]\ttrain-mae:0.01537\tvalid-mae:0.18748\n",
      "[500]\ttrain-mae:0.00846\tvalid-mae:0.18734\n",
      "[600]\ttrain-mae:0.00476\tvalid-mae:0.18735\n",
      "[700]\ttrain-mae:0.00270\tvalid-mae:0.18731\n",
      "[800]\ttrain-mae:0.00158\tvalid-mae:0.18730\n",
      "[900]\ttrain-mae:0.00095\tvalid-mae:0.18729\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.18730\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18730\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18730\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18730\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18730\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.18730\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.18730\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.18730\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.18730\n",
      "[1837]\ttrain-mae:0.00053\tvalid-mae:0.18730\n",
      "  ğŸ” Fold MAE: 0.1873\n",
      "\n",
      "ğŸ” Seed 999 - Fold 3/20\n",
      "[0]\ttrain-mae:0.20252\tvalid-mae:0.22742\n",
      "[100]\ttrain-mae:0.10476\tvalid-mae:0.22455\n",
      "[200]\ttrain-mae:0.05311\tvalid-mae:0.22375\n",
      "[300]\ttrain-mae:0.02779\tvalid-mae:0.22326\n",
      "[400]\ttrain-mae:0.01497\tvalid-mae:0.22346\n",
      "[500]\ttrain-mae:0.00820\tvalid-mae:0.22341\n",
      "[600]\ttrain-mae:0.00465\tvalid-mae:0.22336\n",
      "[700]\ttrain-mae:0.00267\tvalid-mae:0.22340\n",
      "[800]\ttrain-mae:0.00156\tvalid-mae:0.22339\n",
      "[900]\ttrain-mae:0.00094\tvalid-mae:0.22341\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.22341\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.22341\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.22341\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.22341\n",
      "[1306]\ttrain-mae:0.00057\tvalid-mae:0.22341\n",
      "  ğŸ” Fold MAE: 0.2234\n",
      "\n",
      "ğŸ” Seed 999 - Fold 4/20\n",
      "[0]\ttrain-mae:0.20339\tvalid-mae:0.21049\n",
      "[100]\ttrain-mae:0.10482\tvalid-mae:0.20060\n",
      "[200]\ttrain-mae:0.05628\tvalid-mae:0.19759\n",
      "[300]\ttrain-mae:0.03056\tvalid-mae:0.19701\n",
      "[400]\ttrain-mae:0.01674\tvalid-mae:0.19662\n",
      "[500]\ttrain-mae:0.00954\tvalid-mae:0.19667\n",
      "[600]\ttrain-mae:0.00541\tvalid-mae:0.19661\n",
      "[700]\ttrain-mae:0.00315\tvalid-mae:0.19658\n",
      "[800]\ttrain-mae:0.00183\tvalid-mae:0.19656\n",
      "[900]\ttrain-mae:0.00111\tvalid-mae:0.19656\n",
      "[1000]\ttrain-mae:0.00070\tvalid-mae:0.19655\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.19655\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.19656\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19656\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.19655\n",
      "[1500]\ttrain-mae:0.00054\tvalid-mae:0.19655\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19655\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19655\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.19655\n",
      "[1852]\ttrain-mae:0.00053\tvalid-mae:0.19655\n",
      "  ğŸ” Fold MAE: 0.1966\n",
      "\n",
      "ğŸ” Seed 999 - Fold 5/20\n",
      "[0]\ttrain-mae:0.20436\tvalid-mae:0.19116\n",
      "[100]\ttrain-mae:0.10384\tvalid-mae:0.18683\n",
      "[200]\ttrain-mae:0.05419\tvalid-mae:0.18738\n",
      "[300]\ttrain-mae:0.02915\tvalid-mae:0.18847\n",
      "[400]\ttrain-mae:0.01599\tvalid-mae:0.18883\n",
      "[500]\ttrain-mae:0.00893\tvalid-mae:0.18911\n",
      "[600]\ttrain-mae:0.00497\tvalid-mae:0.18925\n",
      "[700]\ttrain-mae:0.00287\tvalid-mae:0.18934\n",
      "[800]\ttrain-mae:0.00165\tvalid-mae:0.18938\n",
      "[900]\ttrain-mae:0.00100\tvalid-mae:0.18942\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.18943\n",
      "[1069]\ttrain-mae:0.00062\tvalid-mae:0.18943\n",
      "  ğŸ” Fold MAE: 0.1894\n",
      "\n",
      "ğŸ” Seed 999 - Fold 6/20\n",
      "[0]\ttrain-mae:0.20343\tvalid-mae:0.21006\n",
      "[100]\ttrain-mae:0.10545\tvalid-mae:0.20324\n",
      "[200]\ttrain-mae:0.05423\tvalid-mae:0.20080\n",
      "[300]\ttrain-mae:0.02880\tvalid-mae:0.19922\n",
      "[400]\ttrain-mae:0.01571\tvalid-mae:0.19888\n",
      "[500]\ttrain-mae:0.00879\tvalid-mae:0.19858\n",
      "[600]\ttrain-mae:0.00502\tvalid-mae:0.19846\n",
      "[700]\ttrain-mae:0.00282\tvalid-mae:0.19838\n",
      "[800]\ttrain-mae:0.00163\tvalid-mae:0.19833\n",
      "[900]\ttrain-mae:0.00098\tvalid-mae:0.19829\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19828\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19828\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19828\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19828\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19828\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19828\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19828\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19828\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19828\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.19828\n",
      "[1999]\ttrain-mae:0.00053\tvalid-mae:0.19827\n",
      "  ğŸ” Fold MAE: 0.1983\n",
      "\n",
      "ğŸ” Seed 999 - Fold 7/20\n",
      "[0]\ttrain-mae:0.20383\tvalid-mae:0.19921\n",
      "[100]\ttrain-mae:0.10423\tvalid-mae:0.19419\n",
      "[200]\ttrain-mae:0.05460\tvalid-mae:0.19250\n",
      "[300]\ttrain-mae:0.02829\tvalid-mae:0.19208\n",
      "[400]\ttrain-mae:0.01508\tvalid-mae:0.19188\n",
      "[500]\ttrain-mae:0.00862\tvalid-mae:0.19180\n",
      "[600]\ttrain-mae:0.00497\tvalid-mae:0.19178\n",
      "[700]\ttrain-mae:0.00289\tvalid-mae:0.19179\n",
      "[800]\ttrain-mae:0.00169\tvalid-mae:0.19177\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.19175\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19175\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19175\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19174\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.19174\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19174\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19174\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.19174\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19174\n",
      "[1800]\ttrain-mae:0.00053\tvalid-mae:0.19174\n",
      "[1900]\ttrain-mae:0.00053\tvalid-mae:0.19174\n",
      "[1999]\ttrain-mae:0.00052\tvalid-mae:0.19174\n",
      "  ğŸ” Fold MAE: 0.1917\n",
      "\n",
      "ğŸ” Seed 999 - Fold 8/20\n",
      "[0]\ttrain-mae:0.20376\tvalid-mae:0.20566\n",
      "[100]\ttrain-mae:0.10913\tvalid-mae:0.19914\n",
      "[200]\ttrain-mae:0.05692\tvalid-mae:0.20017\n",
      "[300]\ttrain-mae:0.03064\tvalid-mae:0.20051\n",
      "[400]\ttrain-mae:0.01680\tvalid-mae:0.20110\n",
      "[500]\ttrain-mae:0.00958\tvalid-mae:0.20135\n",
      "[600]\ttrain-mae:0.00544\tvalid-mae:0.20155\n",
      "[700]\ttrain-mae:0.00310\tvalid-mae:0.20164\n",
      "[800]\ttrain-mae:0.00182\tvalid-mae:0.20169\n",
      "[900]\ttrain-mae:0.00107\tvalid-mae:0.20170\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.20172\n",
      "[1093]\ttrain-mae:0.00059\tvalid-mae:0.20172\n",
      "  ğŸ” Fold MAE: 0.2017\n",
      "\n",
      "ğŸ” Seed 999 - Fold 9/20\n",
      "[0]\ttrain-mae:0.20352\tvalid-mae:0.20323\n",
      "[100]\ttrain-mae:0.10155\tvalid-mae:0.20290\n",
      "[200]\ttrain-mae:0.05352\tvalid-mae:0.20328\n",
      "[300]\ttrain-mae:0.02752\tvalid-mae:0.20449\n",
      "[400]\ttrain-mae:0.01496\tvalid-mae:0.20477\n",
      "[500]\ttrain-mae:0.00814\tvalid-mae:0.20516\n",
      "[600]\ttrain-mae:0.00463\tvalid-mae:0.20532\n",
      "[700]\ttrain-mae:0.00269\tvalid-mae:0.20541\n",
      "[800]\ttrain-mae:0.00158\tvalid-mae:0.20543\n",
      "[900]\ttrain-mae:0.00094\tvalid-mae:0.20546\n",
      "[1000]\ttrain-mae:0.00065\tvalid-mae:0.20547\n",
      "[1071]\ttrain-mae:0.00061\tvalid-mae:0.20547\n",
      "  ğŸ” Fold MAE: 0.2055\n",
      "\n",
      "ğŸ” Seed 999 - Fold 10/20\n",
      "[0]\ttrain-mae:0.20313\tvalid-mae:0.21166\n",
      "[100]\ttrain-mae:0.10157\tvalid-mae:0.20288\n",
      "[200]\ttrain-mae:0.05331\tvalid-mae:0.19977\n",
      "[300]\ttrain-mae:0.02918\tvalid-mae:0.19883\n",
      "[400]\ttrain-mae:0.01689\tvalid-mae:0.19872\n",
      "[500]\ttrain-mae:0.00953\tvalid-mae:0.19855\n",
      "[600]\ttrain-mae:0.00543\tvalid-mae:0.19851\n",
      "[700]\ttrain-mae:0.00319\tvalid-mae:0.19847\n",
      "[800]\ttrain-mae:0.00186\tvalid-mae:0.19845\n",
      "[900]\ttrain-mae:0.00112\tvalid-mae:0.19843\n",
      "[1000]\ttrain-mae:0.00073\tvalid-mae:0.19843\n",
      "[1100]\ttrain-mae:0.00062\tvalid-mae:0.19843\n",
      "[1200]\ttrain-mae:0.00059\tvalid-mae:0.19843\n",
      "[1300]\ttrain-mae:0.00058\tvalid-mae:0.19843\n",
      "[1400]\ttrain-mae:0.00057\tvalid-mae:0.19843\n",
      "[1500]\ttrain-mae:0.00056\tvalid-mae:0.19843\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19843\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19843\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19843\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19843\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19843\n",
      "  ğŸ” Fold MAE: 0.1984\n",
      "\n",
      "ğŸ” Seed 999 - Fold 11/20\n",
      "[0]\ttrain-mae:0.20336\tvalid-mae:0.20895\n",
      "[100]\ttrain-mae:0.10636\tvalid-mae:0.20128\n",
      "[200]\ttrain-mae:0.05587\tvalid-mae:0.19965\n",
      "[300]\ttrain-mae:0.03061\tvalid-mae:0.19933\n",
      "[400]\ttrain-mae:0.01640\tvalid-mae:0.19934\n",
      "[500]\ttrain-mae:0.00907\tvalid-mae:0.19942\n",
      "[600]\ttrain-mae:0.00514\tvalid-mae:0.19939\n",
      "[700]\ttrain-mae:0.00291\tvalid-mae:0.19938\n",
      "[800]\ttrain-mae:0.00169\tvalid-mae:0.19936\n",
      "[900]\ttrain-mae:0.00102\tvalid-mae:0.19939\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.19939\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19939\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19939\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19939\n",
      "[1317]\ttrain-mae:0.00056\tvalid-mae:0.19939\n",
      "  ğŸ” Fold MAE: 0.1994\n",
      "\n",
      "ğŸ” Seed 999 - Fold 12/20\n",
      "[0]\ttrain-mae:0.20411\tvalid-mae:0.19373\n",
      "[100]\ttrain-mae:0.10477\tvalid-mae:0.18561\n",
      "[200]\ttrain-mae:0.05488\tvalid-mae:0.18565\n",
      "[300]\ttrain-mae:0.02904\tvalid-mae:0.18572\n",
      "[400]\ttrain-mae:0.01584\tvalid-mae:0.18593\n",
      "[500]\ttrain-mae:0.00885\tvalid-mae:0.18600\n",
      "[600]\ttrain-mae:0.00506\tvalid-mae:0.18613\n",
      "[700]\ttrain-mae:0.00286\tvalid-mae:0.18616\n",
      "[800]\ttrain-mae:0.00162\tvalid-mae:0.18615\n",
      "[900]\ttrain-mae:0.00098\tvalid-mae:0.18615\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.18615\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18615\n",
      "[1132]\ttrain-mae:0.00060\tvalid-mae:0.18615\n",
      "  ğŸ” Fold MAE: 0.1861\n",
      "\n",
      "ğŸ” Seed 999 - Fold 13/20\n",
      "[0]\ttrain-mae:0.20330\tvalid-mae:0.20950\n",
      "[100]\ttrain-mae:0.10380\tvalid-mae:0.20117\n",
      "[200]\ttrain-mae:0.05264\tvalid-mae:0.19873\n",
      "[300]\ttrain-mae:0.02745\tvalid-mae:0.19776\n",
      "[400]\ttrain-mae:0.01497\tvalid-mae:0.19752\n",
      "[500]\ttrain-mae:0.00856\tvalid-mae:0.19740\n",
      "[600]\ttrain-mae:0.00483\tvalid-mae:0.19737\n",
      "[700]\ttrain-mae:0.00276\tvalid-mae:0.19734\n",
      "[800]\ttrain-mae:0.00161\tvalid-mae:0.19731\n",
      "[900]\ttrain-mae:0.00096\tvalid-mae:0.19731\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.19731\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.19731\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19731\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19731\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19731\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19731\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19731\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.19731\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19730\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19730\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.19730\n",
      "  ğŸ” Fold MAE: 0.1973\n",
      "\n",
      "ğŸ” Seed 999 - Fold 14/20\n",
      "[0]\ttrain-mae:0.20375\tvalid-mae:0.19774\n",
      "[100]\ttrain-mae:0.10286\tvalid-mae:0.19078\n",
      "[200]\ttrain-mae:0.05409\tvalid-mae:0.18805\n",
      "[300]\ttrain-mae:0.02960\tvalid-mae:0.18728\n",
      "[400]\ttrain-mae:0.01666\tvalid-mae:0.18731\n",
      "[500]\ttrain-mae:0.00931\tvalid-mae:0.18718\n",
      "[600]\ttrain-mae:0.00531\tvalid-mae:0.18720\n",
      "[700]\ttrain-mae:0.00308\tvalid-mae:0.18713\n",
      "[800]\ttrain-mae:0.00175\tvalid-mae:0.18711\n",
      "[900]\ttrain-mae:0.00105\tvalid-mae:0.18711\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.18709\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.18709\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.18710\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.18710\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.18710\n",
      "[1445]\ttrain-mae:0.00055\tvalid-mae:0.18710\n",
      "  ğŸ” Fold MAE: 0.1871\n",
      "\n",
      "ğŸ” Seed 999 - Fold 15/20\n",
      "[0]\ttrain-mae:0.20330\tvalid-mae:0.20748\n",
      "[100]\ttrain-mae:0.10203\tvalid-mae:0.20160\n",
      "[200]\ttrain-mae:0.05230\tvalid-mae:0.20028\n",
      "[300]\ttrain-mae:0.02806\tvalid-mae:0.19928\n",
      "[400]\ttrain-mae:0.01537\tvalid-mae:0.19930\n",
      "[500]\ttrain-mae:0.00863\tvalid-mae:0.19922\n",
      "[600]\ttrain-mae:0.00496\tvalid-mae:0.19925\n",
      "[700]\ttrain-mae:0.00288\tvalid-mae:0.19919\n",
      "[800]\ttrain-mae:0.00172\tvalid-mae:0.19915\n",
      "[900]\ttrain-mae:0.00103\tvalid-mae:0.19913\n",
      "[1000]\ttrain-mae:0.00068\tvalid-mae:0.19913\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.19913\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.19913\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.19913\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.19913\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.19913\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.19913\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.19913\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.19913\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.19913\n",
      "[1939]\ttrain-mae:0.00054\tvalid-mae:0.19913\n",
      "  ğŸ” Fold MAE: 0.1991\n",
      "\n",
      "ğŸ” Seed 999 - Fold 16/20\n",
      "[0]\ttrain-mae:0.20381\tvalid-mae:0.20462\n",
      "[100]\ttrain-mae:0.10540\tvalid-mae:0.20128\n",
      "[200]\ttrain-mae:0.05363\tvalid-mae:0.20308\n",
      "[300]\ttrain-mae:0.02805\tvalid-mae:0.20397\n",
      "[400]\ttrain-mae:0.01526\tvalid-mae:0.20432\n",
      "[500]\ttrain-mae:0.00848\tvalid-mae:0.20444\n",
      "[600]\ttrain-mae:0.00464\tvalid-mae:0.20456\n",
      "[700]\ttrain-mae:0.00263\tvalid-mae:0.20458\n",
      "[800]\ttrain-mae:0.00148\tvalid-mae:0.20465\n",
      "[900]\ttrain-mae:0.00088\tvalid-mae:0.20466\n",
      "[1000]\ttrain-mae:0.00064\tvalid-mae:0.20467\n",
      "[1089]\ttrain-mae:0.00059\tvalid-mae:0.20467\n",
      "  ğŸ” Fold MAE: 0.2047\n",
      "\n",
      "ğŸ” Seed 999 - Fold 17/20\n",
      "[0]\ttrain-mae:0.20368\tvalid-mae:0.20734\n",
      "[100]\ttrain-mae:0.10557\tvalid-mae:0.19432\n",
      "[200]\ttrain-mae:0.05478\tvalid-mae:0.19110\n",
      "[300]\ttrain-mae:0.02935\tvalid-mae:0.18994\n",
      "[400]\ttrain-mae:0.01605\tvalid-mae:0.18963\n",
      "[500]\ttrain-mae:0.00875\tvalid-mae:0.18942\n",
      "[600]\ttrain-mae:0.00502\tvalid-mae:0.18931\n",
      "[700]\ttrain-mae:0.00290\tvalid-mae:0.18926\n",
      "[800]\ttrain-mae:0.00171\tvalid-mae:0.18923\n",
      "[900]\ttrain-mae:0.00103\tvalid-mae:0.18920\n",
      "[1000]\ttrain-mae:0.00069\tvalid-mae:0.18919\n",
      "[1100]\ttrain-mae:0.00061\tvalid-mae:0.18919\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18918\n",
      "[1300]\ttrain-mae:0.00057\tvalid-mae:0.18918\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.18918\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.18918\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.18918\n",
      "[1700]\ttrain-mae:0.00055\tvalid-mae:0.18918\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18918\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.18918\n",
      "[1999]\ttrain-mae:0.00054\tvalid-mae:0.18918\n",
      "  ğŸ” Fold MAE: 0.1892\n",
      "\n",
      "ğŸ” Seed 999 - Fold 18/20\n",
      "[0]\ttrain-mae:0.20414\tvalid-mae:0.19485\n",
      "[100]\ttrain-mae:0.10510\tvalid-mae:0.18639\n",
      "[200]\ttrain-mae:0.05447\tvalid-mae:0.18473\n",
      "[300]\ttrain-mae:0.02900\tvalid-mae:0.18475\n",
      "[400]\ttrain-mae:0.01604\tvalid-mae:0.18459\n",
      "[500]\ttrain-mae:0.00894\tvalid-mae:0.18461\n",
      "[600]\ttrain-mae:0.00500\tvalid-mae:0.18457\n",
      "[700]\ttrain-mae:0.00290\tvalid-mae:0.18455\n",
      "[800]\ttrain-mae:0.00169\tvalid-mae:0.18454\n",
      "[900]\ttrain-mae:0.00098\tvalid-mae:0.18453\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.18452\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.18452\n",
      "[1200]\ttrain-mae:0.00058\tvalid-mae:0.18452\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.18452\n",
      "[1400]\ttrain-mae:0.00055\tvalid-mae:0.18452\n",
      "[1500]\ttrain-mae:0.00054\tvalid-mae:0.18452\n",
      "[1600]\ttrain-mae:0.00054\tvalid-mae:0.18452\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.18452\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.18452\n",
      "[1900]\ttrain-mae:0.00054\tvalid-mae:0.18452\n",
      "[1994]\ttrain-mae:0.00053\tvalid-mae:0.18452\n",
      "  ğŸ” Fold MAE: 0.1845\n",
      "\n",
      "ğŸ” Seed 999 - Fold 19/20\n",
      "[0]\ttrain-mae:0.20384\tvalid-mae:0.19643\n",
      "[100]\ttrain-mae:0.10328\tvalid-mae:0.18933\n",
      "[200]\ttrain-mae:0.05371\tvalid-mae:0.18941\n",
      "[300]\ttrain-mae:0.02828\tvalid-mae:0.18920\n",
      "[400]\ttrain-mae:0.01515\tvalid-mae:0.18916\n",
      "[500]\ttrain-mae:0.00866\tvalid-mae:0.18909\n",
      "[600]\ttrain-mae:0.00500\tvalid-mae:0.18912\n",
      "[700]\ttrain-mae:0.00283\tvalid-mae:0.18916\n",
      "[800]\ttrain-mae:0.00166\tvalid-mae:0.18916\n",
      "[900]\ttrain-mae:0.00099\tvalid-mae:0.18916\n",
      "[1000]\ttrain-mae:0.00066\tvalid-mae:0.18916\n",
      "[1100]\ttrain-mae:0.00059\tvalid-mae:0.18915\n",
      "[1113]\ttrain-mae:0.00058\tvalid-mae:0.18915\n",
      "  ğŸ” Fold MAE: 0.1892\n",
      "\n",
      "ğŸ” Seed 999 - Fold 20/20\n",
      "[0]\ttrain-mae:0.20325\tvalid-mae:0.21073\n",
      "[100]\ttrain-mae:0.10575\tvalid-mae:0.20268\n",
      "[200]\ttrain-mae:0.05536\tvalid-mae:0.20147\n",
      "[300]\ttrain-mae:0.02952\tvalid-mae:0.20107\n",
      "[400]\ttrain-mae:0.01621\tvalid-mae:0.20082\n",
      "[500]\ttrain-mae:0.00912\tvalid-mae:0.20079\n",
      "[600]\ttrain-mae:0.00504\tvalid-mae:0.20068\n",
      "[700]\ttrain-mae:0.00291\tvalid-mae:0.20069\n",
      "[800]\ttrain-mae:0.00167\tvalid-mae:0.20068\n",
      "[900]\ttrain-mae:0.00101\tvalid-mae:0.20067\n",
      "[1000]\ttrain-mae:0.00067\tvalid-mae:0.20067\n",
      "[1100]\ttrain-mae:0.00060\tvalid-mae:0.20066\n",
      "[1200]\ttrain-mae:0.00057\tvalid-mae:0.20066\n",
      "[1300]\ttrain-mae:0.00056\tvalid-mae:0.20066\n",
      "[1400]\ttrain-mae:0.00056\tvalid-mae:0.20066\n",
      "[1500]\ttrain-mae:0.00055\tvalid-mae:0.20067\n",
      "[1600]\ttrain-mae:0.00055\tvalid-mae:0.20067\n",
      "[1700]\ttrain-mae:0.00054\tvalid-mae:0.20067\n",
      "[1800]\ttrain-mae:0.00054\tvalid-mae:0.20067\n",
      "[1849]\ttrain-mae:0.00054\tvalid-mae:0.20067\n",
      "  ğŸ” Fold MAE: 0.2007\n",
      "\n",
      "âœ… ëª¨ë“  Seed-Fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "ğŸ“‰ í‰ê·  MAE (Across All Seeds): 0.1957\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "X = train[features]\n",
    "y = train['ì„±ê³µí™•ë¥ ']\n",
    "\n",
    "# âœ… ì—¬ëŸ¬ ê°œ seed ì„¤ì •\n",
    "seeds = [13, 42, 77, 123, 999]\n",
    "n_splits = 20\n",
    "\n",
    "models = []\n",
    "cv_scores = []\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 19,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'lambda': 0,\n",
    "    'alpha': 0,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "# âœ… seedë§ˆë‹¤ KFold 10íšŒì”© ì‹¤í–‰\n",
    "for seed in seeds:\n",
    "    print(f\"\\nğŸ§ª Seed {seed} ì‹œì‘\")\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nğŸ” Seed {seed} - Fold {fold+1}/{n_splits}\")\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "        model = xgb.train(\n",
    "            params={**params, 'seed': seed},\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=2000,\n",
    "            evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "            early_stopping_rounds=1000,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "\n",
    "        preds = model.predict(dvalid)\n",
    "        score = mean_absolute_error(y_valid, preds)\n",
    "        print(f\"  ğŸ” Fold MAE: {score:.4f}\")\n",
    "\n",
    "        models.append(model)\n",
    "        cv_scores.append(score)\n",
    "\n",
    "# âœ… ì „ì²´ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nâœ… ëª¨ë“  Seed-Fold ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“‰ í‰ê·  MAE (Across All Seeds): {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n",
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n",
      "Predict with fold 6\n",
      "Predict with fold 7\n",
      "Predict with fold 8\n",
      "Predict with fold 9\n",
      "Predict with fold 10\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# ì €ì¥ëœ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡\n",
    "predictions_list = []\n",
    "\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(dtest)  # DMatrix ì…ë ¥\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# í‰ê·  ì˜ˆì¸¡\n",
    "final_predictions = np.mean(predictions_list, axis=0)\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_predictions\n",
    "sample_submission.to_csv('./0416_14_submission.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n",
      "Predict with fold 2\n",
      "Predict with fold 3\n",
      "Predict with fold 4\n",
      "Predict with fold 5\n",
      "Predict with fold 6\n",
      "Predict with fold 7\n",
      "Predict with fold 8\n",
      "Predict with fold 9\n",
      "Predict with fold 10\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# ì €ì¥ëœ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡\n",
    "predictions_list = []\n",
    "dtest = xgb.DMatrix(test[features])  # í…ŒìŠ¤íŠ¸ì…‹ ë³€í™˜\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(dtest)\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# ğŸ¯ MAEì˜ ì—­ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš© (MAEê°€ ë‚®ì„ìˆ˜ë¡ ë” ë†’ì€ ê°€ì¤‘ì¹˜)\n",
    "weights = 1 / np.array(cv_scores)\n",
    "weights = weights / weights.sum()  # ì •ê·œí™”\n",
    "\n",
    "# ğŸ¯ ê°€ì¤‘ í‰ê·  ê³„ì‚°\n",
    "final_predictions = np.average(predictions_list, axis=0, weights=weights)\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ì €ì¥\n",
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_predictions\n",
    "sample_submission.to_csv('./0414_19_submission.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
